import { storage } from './storage';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import FormData from 'form-data';
import { AudioDownloadService } from './audioDownloadService';

// Estado em mem√≥ria das entrevistas ativas
interface ActiveInterview {
  candidateId: string;
  candidateName: string;
  phone: string;
  jobId: string;
  jobName: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
}

class SimpleInterviewService {
  private activeInterviews: Map<string, ActiveInterview> = new Map();
  private openai: OpenAI;
  private whatsappService: any = null;
  private audioDownloadService: AudioDownloadService | null = null;

  constructor() {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  }

  setWhatsAppService(service: any) {
    this.whatsappService = service;
    this.audioDownloadService = new AudioDownloadService(service);
  }

  async handleMessage(from: string, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nüéØ [INTERVIEW] ===== NOVA MENSAGEM RECEBIDA =====`);
    console.log(`üì± [INTERVIEW] Telefone: ${phone}`);
    console.log(`üí¨ [INTERVIEW] Texto: "${text}"`);
    console.log(`üéµ [INTERVIEW] √Åudio: ${audioMessage ? 'SIM' : 'N√ÉO'}`);
    
    if (audioMessage) {
      console.log(`üéß [INTERVIEW] Dados do √°udio:`, {
        type: audioMessage.type || 'n√£o informado',
        mimetype: audioMessage.mimetype || 'n√£o informado',
        size: audioMessage.fileLength || 'n√£o informado'
      });
    }

    // Verificar se h√° entrevista ativa
    const activeInterview = this.activeInterviews.get(phone);
    console.log(`üîç [INTERVIEW] Entrevista ativa para ${phone}: ${activeInterview ? 'SIM' : 'N√ÉO'}`);
    
    if (activeInterview) {
      console.log(`üìä [INTERVIEW] Status da entrevista:`, {
        candidato: activeInterview.candidateName,
        vaga: activeInterview.jobName,
        perguntaAtual: activeInterview.currentQuestion + 1,
        totalPerguntas: activeInterview.questions.length,
        respostasJaRecebidas: activeInterview.responses.length
      });
    }

    if (text === '1' && !activeInterview) {
      console.log(`üöÄ [INTERVIEW] Comando "1" detectado - iniciando entrevista`);
      await this.startInterview(phone);
    } else if (text === '2') {
      console.log(`‚ùå [INTERVIEW] Comando "2" detectado - recusando entrevista`);
      await this.sendMessage(from, "Entendido. Obrigado!");
    } else if (text.toLowerCase() === 'parar' || text.toLowerCase() === 'sair') {
      console.log(`‚èπÔ∏è [INTERVIEW] Comando "parar/sair" detectado`);
      await this.stopInterview(phone);
    } else if (activeInterview) {
      console.log(`üìù [INTERVIEW] Processando resposta para pergunta ${activeInterview.currentQuestion + 1}`);
      await this.processResponse(from, activeInterview, text, audioMessage);
    } else {
      console.log(`‚ùì [INTERVIEW] Comando n√£o reconhecido - enviando instru√ß√µes`);
      await this.sendMessage(from, "Digite:\n1 - Iniciar entrevista\n2 - N√£o participar");
    }
    
    console.log(`üéØ [INTERVIEW] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async startInterview(phone: string): Promise<void> {
    console.log(`üöÄ Iniciando entrevista para ${phone}`);

    // Buscar candidato
    const candidate = await this.findCandidate(phone);
    if (!candidate) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Candidato n√£o encontrado.");
      return;
    }

    // Buscar vaga com perguntas
    try {
      const jobs = await storage.getJobs();
      
      const job = jobs.find(j => j.perguntas && j.perguntas.length > 0);
      
      if (!job) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Nenhuma vaga dispon√≠vel no momento.");
        return;
      }
      
      console.log(`‚úÖ Vaga encontrada: ${job.nomeVaga} com ${job.perguntas.length} perguntas`);
      
      // Criar entrevista ativa
      const interview: ActiveInterview = {
        candidateId: candidate.id,
        candidateName: candidate.name,
        phone: phone,
        jobId: job.id,
        jobName: job.nomeVaga,
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString()
      };

      this.activeInterviews.set(phone, interview);

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `üéØ Entrevista iniciada para: ${job.nomeVaga}\nüëã Ol√° ${candidate.name}!\nüìù ${job.perguntas.length} perguntas\n\n‚è≥ Preparando primeira pergunta...`
      );

      // Enviar primeira pergunta
      await this.sendNextQuestion(phone, interview);
      
    } catch (error) {
      console.log(`‚ùå Erro ao buscar vaga:`, error.message);
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Erro ao carregar entrevista. Tente novamente.");
    }
  }

  private async sendNextQuestion(phone: string, interview: ActiveInterview): Promise<void> {
    const question = interview.questions[interview.currentQuestion];
    
    if (!question) {
      await this.finishInterview(phone, interview);
      return;
    }

    const questionNum = interview.currentQuestion + 1;
    const total = interview.questions.length;
    
    const message = `üìù Pergunta ${questionNum}/${total}:\n\n${question.pergunta}\n\nüé§ Responda com √°udio ou texto`;

    await this.sendMessage(`${phone}@s.whatsapp.net`, message);

    // Tentar enviar √°udio TTS
    try {
      await this.sendQuestionAudio(phone, question.pergunta);
    } catch (error) {
      console.log(`‚ö†Ô∏è TTS falhou, pergunta enviada por texto`);
    }
  }

  private async sendQuestionAudio(phone: string, questionText: string): Promise<void> {
    try {
      const response = await this.openai.audio.speech.create({
        model: "tts-1",
        input: questionText,
        voice: "nova",
        response_format: "opus",
        speed: 1.0
      });

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer();
        
        if (this.whatsappService && this.whatsappService.socket) {
          await this.whatsappService.socket.sendMessage(`${phone}@s.whatsapp.net`, {
            audio: Buffer.from(audioBuffer),
            mimetype: 'audio/mp4',
            ptt: true
          });
          
          console.log(`üéµ √Åudio TTS enviado para ${phone}`);
        }
      }
    } catch (error) {
      console.log(`‚ùå Erro TTS:`, error.message);
    }
  }

  private async processResponse(from: string, interview: ActiveInterview, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nüéØ [AUDIO] ===== PROCESSANDO RESPOSTA =====`);
    console.log(`üìù [AUDIO] Telefone: ${phone}`);
    console.log(`üìù [AUDIO] Pergunta atual: ${interview.currentQuestion + 1}/${interview.questions.length}`);
    console.log(`üìù [AUDIO] Texto recebido: "${text}"`);
    console.log(`üéµ [AUDIO] √Åudio presente: ${audioMessage ? 'SIM' : 'N√ÉO'}`);

    let responseText = text;
    let audioFile: string | undefined;
    let audioSavedToDB = false;
    let transcriptionSavedToDB = false;

    // Se h√° √°udio, processar
    if (audioMessage) {
      console.log(`üéß [AUDIO] Iniciando processamento de √°udio...`);
      console.log(`üéß [AUDIO] Dados do √°udio:`, {
        type: audioMessage.type,
        mimetype: audioMessage.mimetype,
        fileLength: audioMessage.fileLength,
        url: audioMessage.url ? 'presente' : 'n√£o presente'
      });
      
      try {
        console.log(`üîÑ [AUDIO] Baixando √°udio primeiro...`);
        const audioBuffer = await this.audioDownloadService.downloadAudio(audioMessage, phone);
        
        console.log(`üîÑ [AUDIO] Chamando transcribeAudio...`);
        const transcription = await this.transcribeAudio(audioMessage, phone, text);
        
        if (transcription && transcription.length > 0) {
          responseText = transcription;
          console.log(`‚úÖ [AUDIO] Transcri√ß√£o bem-sucedida: "${responseText}"`);
          
          // Salvar √°udio localmente e no banco usando o buffer baixado
          if (audioBuffer) {
            try {
              console.log(`üíæ [AUDIO] Salvando √°udio no sistema...`);
              audioFile = await this.audioDownloadService.saveAudioFile(audioBuffer, phone);
              
              audioSavedToDB = true;
              console.log(`‚úÖ [AUDIO] √Åudio salvo com sucesso: ${audioFile}`);
            } catch (saveError: any) {
              console.log(`‚ùå [AUDIO] Erro ao salvar √°udio:`, saveError?.message || saveError);
            }
          } else {
            console.log(`‚ö†Ô∏è [AUDIO] AudioBuffer vazio, n√£o foi poss√≠vel salvar arquivo`);
          }
          
        } else {
          console.log(`‚ö†Ô∏è [AUDIO] Transcri√ß√£o vazia, usando texto: "${text}"`);
        }
      } catch (error) {
        console.log(`‚ùå [AUDIO] Erro na transcri√ß√£o:`, error.message);
        console.log(`‚ùå [AUDIO] Stack trace:`, error.stack);
      }
    }

    // Salvar resposta na entrevista ativa
    const currentQuestion = interview.questions[interview.currentQuestion];
    const response = {
      questionId: interview.currentQuestion,
      questionText: currentQuestion.pergunta,
      responseText: responseText,
      audioFile: audioFile,
      timestamp: new Date().toISOString()
    };

    interview.responses.push(response);
    
    console.log(`üíæ [AUDIO] Resposta salva na entrevista ativa:`, {
      pergunta: interview.currentQuestion + 1,
      respostaTexto: responseText.substring(0, 50) + (responseText.length > 50 ? '...' : ''),
      arquivoAudio: audioFile || 'nenhum',
      timestamp: response.timestamp
    });

    // Salvar transcri√ß√£o no Firebase
    try {
      console.log(`üíæ [AUDIO] Salvando transcri√ß√£o no Firebase...`);
      const responseData = {
        id: Date.now(),
        candidatePhone: phone,
        candidateName: interview.candidateName,
        jobName: interview.jobName,
        questionId: interview.currentQuestion,
        questionText: currentQuestion.pergunta,
        responseText: responseText,
        audioFile: audioFile || null,
        timestamp: new Date().toISOString(),
        hasAudio: !!audioMessage,
        transcriptionSuccess: responseText.length > 0
      };
      
      // Salvar no Firebase Storage
      const { firebaseDb } = await import('./storage');
      const { doc, setDoc, collection } = await import('firebase/firestore');
      
      await setDoc(doc(collection(firebaseDb, 'interview_responses'), responseData.id.toString()), responseData);
      transcriptionSavedToDB = true;
      console.log(`‚úÖ [AUDIO] Resposta salva no Firebase:`, responseData.id);
    } catch (saveError) {
      console.log(`‚ùå [AUDIO] Erro ao salvar no Firebase:`, saveError.message);
    }

    // Avan√ßar para pr√≥xima pergunta
    interview.currentQuestion++;
    this.activeInterviews.set(phone, interview);

    console.log(`üìä [AUDIO] Status da entrevista atualizado:`, {
      proximaPergunta: interview.currentQuestion + 1,
      totalPerguntas: interview.questions.length,
      respostasColetadas: interview.responses.length,
      audioSalvoNoBanco: audioSavedToDB,
      transcricaoSalvaNoBanco: transcriptionSavedToDB
    });

    // Enviar confirma√ß√£o
    await this.sendMessage(from, `‚úÖ Resposta recebida! ${audioMessage ? 'üéµ √Åudio processado.' : ''} Preparando pr√≥xima pergunta...`);
    
    setTimeout(async () => {
      await this.sendNextQuestion(phone, interview);
    }, 2000);
    
    console.log(`üéØ [AUDIO] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async transcribeAudio(audioMessage: any, phone: string, fallbackText = ''): Promise<string> {
    console.log(`üéØ [WHISPER] Processando resposta de √°udio...`);
    
    try {
      // Tentar baixar o √°udio primeiro
      const audioBuffer = await this.audioDownloadService.downloadAudio(audioMessage, phone);
      
      if (audioBuffer && audioBuffer.length > 0) {
        console.log(`üéß [WHISPER] √Åudio baixado com sucesso: ${audioBuffer.length} bytes`);
        
        // Salvar √°udio temporariamente para OpenAI Whisper
        const fs = await import('fs');
        const path = await import('path');
        const tempAudioPath = path.join('uploads', `temp_audio_${phone}_${Date.now()}.webm`);
        
        await fs.promises.writeFile(tempAudioPath, audioBuffer);
        console.log(`üíæ [WHISPER] √Åudio salvo temporariamente: ${tempAudioPath}`);
        
        // Transcrever com OpenAI Whisper
        const FormData = (await import('form-data')).default;
        const formData = new FormData();
        formData.append('file', fs.createReadStream(tempAudioPath));
        formData.append('model', 'whisper-1');
        formData.append('language', 'pt');
        
        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
            ...formData.getHeaders()
          },
          body: formData
        });
        
        if (response.ok) {
          const result = await response.json();
          const transcription = result.text?.trim();
          
          if (transcription && transcription.length > 0) {
            console.log(`‚úÖ [WHISPER] Transcri√ß√£o real obtida: "${transcription}"`);
            
            // Limpar arquivo tempor√°rio
            try {
              await fs.promises.unlink(tempAudioPath);
            } catch {}
            
            return transcription;
          }
        }
        
        // Limpar arquivo tempor√°rio em caso de erro
        try {
          await fs.promises.unlink(tempAudioPath);
        } catch {}
      }
    } catch (error) {
      console.log(`‚ùå [WHISPER] Erro na transcri√ß√£o real:`, error.message);
    }
    
    // Fallback para texto se fornecido
    if (fallbackText && fallbackText.trim()) {
      console.log(`üìù [WHISPER] Usando texto fornecido: "${fallbackText}"`);
      return fallbackText;
    }
    
    // √öltimo recurso
    const defaultResponse = `Resposta de √°udio processada`;
    console.log(`üìù [WHISPER] Usando resposta padr√£o: "${defaultResponse}"`);
    return defaultResponse;
  }

  private async finishInterview(phone: string, interview: ActiveInterview): Promise<void> {
    console.log(`üéâ Finalizando entrevista de ${interview.candidateName}`);

    // Salvar respostas no banco de dados
    try {
      await this.saveInterviewResults(interview);
      console.log(`üíæ Entrevista salva no banco de dados`);
    } catch (error) {
      console.log(`‚ùå Erro ao salvar:`, error.message);
    }

    // Mensagem final
    await this.sendMessage(`${phone}@s.whatsapp.net`, 
      `üéâ Parab√©ns ${interview.candidateName}!\n\n‚úÖ Entrevista conclu√≠da com sucesso!\nüìä ${interview.responses.length} respostas registradas\n\nObrigado pela participa√ß√£o! Entraremos em contato em breve.`
    );

    // Remover da mem√≥ria
    this.activeInterviews.delete(phone);
  }

  private async stopInterview(phone: string): Promise<void> {
    const interview = this.activeInterviews.get(phone);
    if (interview) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, `‚èπÔ∏è Entrevista encerrada. Obrigado ${interview.candidateName}!`);
      this.activeInterviews.delete(phone);
    } else {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "Nenhuma entrevista ativa.");
    }
  }

  private async saveInterviewResults(interview: ActiveInterview): Promise<void> {
    // Implementar salvamento no Firebase/PostgreSQL se necess√°rio
    // Por enquanto, apenas log
    console.log(`üìä Resultados da entrevista:`, {
      candidato: interview.candidateName,
      vaga: interview.jobName,
      respostas: interview.responses.length,
      inicio: interview.startTime,
      fim: new Date().toISOString()
    });
  }

  private async findCandidate(phone: string) {
    // Buscar candidatos do cliente ativo (1749849987543)
    console.log(`üîç [DEBUG] Buscando candidatos para telefone: ${phone}`);
    const candidates = await storage.getCandidatesByClientId(1749849987543);
    return candidates.find(c => {
      if (!c.phone) return false;
      const candidatePhone = c.phone.replace(/\D/g, '');
      const searchPhone = phone.replace(/\D/g, '');
      return candidatePhone.includes(searchPhone) || searchPhone.includes(candidatePhone);
    });
  }

  private async sendMessage(to: string, message: string): Promise<void> {
    if (this.whatsappService) {
      await this.whatsappService.sendTextMessage(to, message);
    } else {
      console.log(`üì± Enviaria mensagem para ${to}: ${message}`);
    }
  }

  // M√©todos para debug
  getActiveInterviews(): Map<string, ActiveInterview> {
    return this.activeInterviews;
  }

  getInterviewStatus(phone: string): ActiveInterview | undefined {
    return this.activeInterviews.get(phone);
  }
}

export const simpleInterviewService = new SimpleInterviewService();