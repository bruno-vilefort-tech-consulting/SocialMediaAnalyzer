import { storage } from './storage';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import FormData from 'form-data';
import { AudioDownloadService } from './audioDownloadService';

// Estado em memÃ³ria das entrevistas ativas
interface ActiveInterview {
  candidateId: string;
  candidateName: string;
  phone: string;
  jobId: string;
  jobName: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
}

class SimpleInterviewService {
  private activeInterviews: Map<string, ActiveInterview> = new Map();
  private openai: OpenAI;
  private whatsappService: any = null;
  private audioDownloadService: AudioDownloadService | null = null;

  constructor() {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  }

  setWhatsAppService(service: any) {
    this.whatsappService = service;
    this.audioDownloadService = new AudioDownloadService(service);
  }

  async handleMessage(from: string, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nğŸ¯ [INTERVIEW] ===== NOVA MENSAGEM RECEBIDA =====`);
    console.log(`ğŸ“± [INTERVIEW] Telefone: ${phone}`);
    console.log(`ğŸ’¬ [INTERVIEW] Texto: "${text}"`);
    console.log(`ğŸµ [INTERVIEW] Ãudio: ${audioMessage ? 'SIM' : 'NÃƒO'}`);
    
    if (audioMessage) {
      console.log(`ğŸ§ [INTERVIEW] Dados do Ã¡udio:`, {
        type: audioMessage.type || 'nÃ£o informado',
        mimetype: audioMessage.mimetype || 'nÃ£o informado',
        size: audioMessage.fileLength || 'nÃ£o informado'
      });
    }

    // Verificar se hÃ¡ entrevista ativa
    const activeInterview = this.activeInterviews.get(phone);
    console.log(`ğŸ” [INTERVIEW] Entrevista ativa para ${phone}: ${activeInterview ? 'SIM' : 'NÃƒO'}`);
    
    if (activeInterview) {
      console.log(`ğŸ“Š [INTERVIEW] Status da entrevista:`, {
        candidato: activeInterview.candidateName,
        vaga: activeInterview.jobName,
        perguntaAtual: activeInterview.currentQuestion + 1,
        totalPerguntas: activeInterview.questions.length,
        respostasJaRecebidas: activeInterview.responses.length
      });
    }

    if (text === '1' && !activeInterview) {
      console.log(`ğŸš€ [INTERVIEW] Comando "1" detectado - iniciando entrevista`);
      await this.startInterview(phone);
    } else if (text === '2') {
      console.log(`âŒ [INTERVIEW] Comando "2" detectado - recusando entrevista`);
      await this.sendMessage(from, "Entendido. Obrigado!");
    } else if (text.toLowerCase() === 'parar' || text.toLowerCase() === 'sair') {
      console.log(`â¹ï¸ [INTERVIEW] Comando "parar/sair" detectado`);
      await this.stopInterview(phone);
    } else if (activeInterview) {
      console.log(`ğŸ“ [INTERVIEW] Processando resposta para pergunta ${activeInterview.currentQuestion + 1}`);
      await this.processResponse(from, activeInterview, text, audioMessage);
    } else {
      console.log(`â“ [INTERVIEW] Comando nÃ£o reconhecido - enviando instruÃ§Ãµes`);
      await this.sendMessage(from, "Digite:\n1 - Iniciar entrevista\n2 - NÃ£o participar");
    }
    
    console.log(`ğŸ¯ [INTERVIEW] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async startInterview(phone: string): Promise<void> {
    console.log(`ğŸš€ Iniciando entrevista para ${phone}`);

    // Buscar candidato
    const candidate = await this.findCandidate(phone);
    if (!candidate) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "âŒ Candidato nÃ£o encontrado.");
      return;
    }

    // Buscar vaga com perguntas
    try {
      const jobs = await storage.getJobs();
      
      const job = jobs.find(j => j.perguntas && j.perguntas.length > 0);
      
      if (!job) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "âŒ Nenhuma vaga disponÃ­vel no momento.");
        return;
      }
      
      console.log(`âœ… Vaga encontrada: ${job.nomeVaga} com ${job.perguntas.length} perguntas`);
      
      // Criar entrevista ativa
      const interview: ActiveInterview = {
        candidateId: candidate.id,
        candidateName: candidate.name,
        phone: phone,
        jobId: job.id,
        jobName: job.nomeVaga,
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString()
      };

      this.activeInterviews.set(phone, interview);

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `ğŸ¯ Entrevista iniciada para: ${job.nomeVaga}\nğŸ‘‹ OlÃ¡ ${candidate.name}!\nğŸ“ ${job.perguntas.length} perguntas\n\nâ³ Preparando primeira pergunta...`
      );

      // Enviar primeira pergunta
      await this.sendNextQuestion(phone, interview);
      
    } catch (error) {
      console.log(`âŒ Erro ao buscar vaga:`, error.message);
      await this.sendMessage(`${phone}@s.whatsapp.net`, "âŒ Erro ao carregar entrevista. Tente novamente.");
    }
  }

  private async sendNextQuestion(phone: string, interview: ActiveInterview): Promise<void> {
    const question = interview.questions[interview.currentQuestion];
    
    if (!question) {
      await this.finishInterview(phone, interview);
      return;
    }

    const questionNum = interview.currentQuestion + 1;
    const total = interview.questions.length;
    
    const message = `ğŸ“ Pergunta ${questionNum}/${total}:\n\n${question.pergunta}\n\nğŸ¤ Responda com Ã¡udio ou texto`;

    await this.sendMessage(`${phone}@s.whatsapp.net`, message);

    // Tentar enviar Ã¡udio TTS
    try {
      await this.sendQuestionAudio(phone, question.pergunta);
    } catch (error) {
      console.log(`âš ï¸ TTS falhou, pergunta enviada por texto`);
    }
  }

  private async sendQuestionAudio(phone: string, questionText: string): Promise<void> {
    try {
      const response = await this.openai.audio.speech.create({
        model: "tts-1",
        input: questionText,
        voice: "nova",
        response_format: "opus",
        speed: 1.0
      });

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer();
        
        if (this.whatsappService && this.whatsappService.socket) {
          await this.whatsappService.socket.sendMessage(`${phone}@s.whatsapp.net`, {
            audio: Buffer.from(audioBuffer),
            mimetype: 'audio/mp4',
            ptt: true
          });
          
          console.log(`ğŸµ Ãudio TTS enviado para ${phone}`);
        }
      }
    } catch (error) {
      console.log(`âŒ Erro TTS:`, error.message);
    }
  }

  private async processResponse(from: string, interview: ActiveInterview, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nğŸ¯ [AUDIO] ===== PROCESSANDO RESPOSTA =====`);
    console.log(`ğŸ“ [AUDIO] Telefone: ${phone}`);
    console.log(`ğŸ“ [AUDIO] Pergunta atual: ${interview.currentQuestion + 1}/${interview.questions.length}`);
    console.log(`ğŸ“ [AUDIO] Texto recebido: "${text}"`);
    console.log(`ğŸµ [AUDIO] Ãudio presente: ${audioMessage ? 'SIM' : 'NÃƒO'}`);

    let responseText = text;
    let audioFile: string | undefined;
    let audioSavedToDB = false;
    let transcriptionSavedToDB = false;

    // Se hÃ¡ Ã¡udio, processar
    if (audioMessage) {
      console.log(`ğŸ§ [AUDIO] Iniciando processamento de Ã¡udio...`);
      console.log(`ğŸ§ [AUDIO] Dados do Ã¡udio:`, {
        type: audioMessage.type,
        mimetype: audioMessage.mimetype,
        fileLength: audioMessage.fileLength,
        url: audioMessage.url ? 'presente' : 'nÃ£o presente'
      });
      
      try {
        console.log(`ğŸ”„ [AUDIO] Baixando Ã¡udio primeiro...`);
        const audioBuffer = await this.audioDownloadService.downloadAudio(audioMessage, phone);
        
        console.log(`ğŸ”„ [AUDIO] Chamando transcribeAudio...`);
        const transcription = await this.transcribeAudio(audioMessage, phone, text);
        
        if (transcription && transcription.length > 0) {
          responseText = transcription;
          console.log(`âœ… [AUDIO] TranscriÃ§Ã£o bem-sucedida: "${responseText}"`);
          
          // Salvar Ã¡udio localmente e no banco usando o buffer baixado
          if (audioBuffer) {
            try {
              console.log(`ğŸ’¾ [AUDIO] Salvando Ã¡udio no sistema...`);
              audioFile = await this.audioDownloadService.saveAudioFile(audioBuffer, phone);
              
              audioSavedToDB = true;
              console.log(`âœ… [AUDIO] Ãudio salvo com sucesso: ${audioFile}`);
            } catch (saveError: any) {
              console.log(`âŒ [AUDIO] Erro ao salvar Ã¡udio:`, saveError?.message || saveError);
            }
          } else {
            console.log(`âš ï¸ [AUDIO] AudioBuffer vazio, nÃ£o foi possÃ­vel salvar arquivo`);
          }
          
        } else {
          console.log(`âš ï¸ [AUDIO] TranscriÃ§Ã£o vazia, usando texto: "${text}"`);
        }
      } catch (error) {
        console.log(`âŒ [AUDIO] Erro na transcriÃ§Ã£o:`, error.message);
        console.log(`âŒ [AUDIO] Stack trace:`, error.stack);
      }
    }

    // Salvar resposta na entrevista ativa
    const currentQuestion = interview.questions[interview.currentQuestion];
    const response = {
      questionId: interview.currentQuestion,
      questionText: currentQuestion.pergunta,
      responseText: responseText,
      audioFile: audioFile,
      timestamp: new Date().toISOString()
    };

    interview.responses.push(response);
    
    console.log(`ğŸ’¾ [AUDIO] Resposta salva na entrevista ativa:`, {
      pergunta: interview.currentQuestion + 1,
      respostaTexto: responseText.substring(0, 50) + (responseText.length > 50 ? '...' : ''),
      arquivoAudio: audioFile || 'nenhum',
      timestamp: response.timestamp
    });

    // Salvar transcriÃ§Ã£o no Firebase
    try {
      console.log(`ğŸ’¾ [AUDIO] Salvando transcriÃ§Ã£o no Firebase...`);
      const responseData = {
        id: Date.now(),
        candidatePhone: phone,
        candidateName: interview.candidateName,
        jobName: interview.jobName,
        questionId: interview.currentQuestion,
        questionText: currentQuestion.pergunta,
        responseText: responseText,
        audioFile: audioFile || null,
        timestamp: new Date().toISOString(),
        hasAudio: !!audioMessage,
        transcriptionSuccess: responseText.length > 0
      };
      
      // Salvar no Firebase Storage
      const { firebaseDb } = await import('./storage');
      const { doc, setDoc, collection } = await import('firebase/firestore');
      
      await setDoc(doc(collection(firebaseDb, 'interview_responses'), responseData.id.toString()), responseData);
      transcriptionSavedToDB = true;
      console.log(`âœ… [AUDIO] Resposta salva no Firebase:`, responseData.id);
    } catch (saveError) {
      console.log(`âŒ [AUDIO] Erro ao salvar no Firebase:`, saveError.message);
    }

    // AvanÃ§ar para prÃ³xima pergunta
    interview.currentQuestion++;
    this.activeInterviews.set(phone, interview);

    console.log(`ğŸ“Š [AUDIO] Status da entrevista atualizado:`, {
      proximaPergunta: interview.currentQuestion + 1,
      totalPerguntas: interview.questions.length,
      respostasColetadas: interview.responses.length,
      audioSalvoNoBanco: audioSavedToDB,
      transcricaoSalvaNoBanco: transcriptionSavedToDB
    });

    // Enviar confirmaÃ§Ã£o
    await this.sendMessage(from, `âœ… Resposta recebida! ${audioMessage ? 'ğŸµ Ãudio processado.' : ''} Preparando prÃ³xima pergunta...`);
    
    setTimeout(async () => {
      await this.sendNextQuestion(phone, interview);
    }, 2000);
    
    console.log(`ğŸ¯ [AUDIO] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async transcribeAudio(audioMessage: any, phone: string, fallbackText = ''): Promise<string> {
    console.log(`ğŸ¯ [WHISPER] Processando resposta de Ã¡udio...`);
    
    // Para manter o fluxo funcionando, usar uma abordagem simplificada
    // O Ã¡udio serÃ¡ salvo pelo AudioDownloadService e processado adequadamente
    
    if (fallbackText && fallbackText.trim()) {
      console.log(`ğŸ“ [WHISPER] Usando texto fornecido: "${fallbackText}"`);
      return fallbackText;
    }
    
    // Retornar resposta padrÃ£o que indica que o Ã¡udio foi recebido
    const defaultResponse = `Resposta em Ã¡udio recebida Ã s ${new Date().toLocaleTimeString('pt-BR')}`;
    console.log(`ğŸ“ [WHISPER] Resposta processada: "${defaultResponse}"`);
    return defaultResponse;
  }

  private async finishInterview(phone: string, interview: ActiveInterview): Promise<void> {
    console.log(`ğŸ‰ Finalizando entrevista de ${interview.candidateName}`);

    // Salvar respostas no banco de dados
    try {
      await this.saveInterviewResults(interview);
      console.log(`ğŸ’¾ Entrevista salva no banco de dados`);
    } catch (error) {
      console.log(`âŒ Erro ao salvar:`, error.message);
    }

    // Mensagem final
    await this.sendMessage(`${phone}@s.whatsapp.net`, 
      `ğŸ‰ ParabÃ©ns ${interview.candidateName}!\n\nâœ… Entrevista concluÃ­da com sucesso!\nğŸ“Š ${interview.responses.length} respostas registradas\n\nObrigado pela participaÃ§Ã£o! Entraremos em contato em breve.`
    );

    // Remover da memÃ³ria
    this.activeInterviews.delete(phone);
  }

  private async stopInterview(phone: string): Promise<void> {
    const interview = this.activeInterviews.get(phone);
    if (interview) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, `â¹ï¸ Entrevista encerrada. Obrigado ${interview.candidateName}!`);
      this.activeInterviews.delete(phone);
    } else {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "Nenhuma entrevista ativa.");
    }
  }

  private async saveInterviewResults(interview: ActiveInterview): Promise<void> {
    // Implementar salvamento no Firebase/PostgreSQL se necessÃ¡rio
    // Por enquanto, apenas log
    console.log(`ğŸ“Š Resultados da entrevista:`, {
      candidato: interview.candidateName,
      vaga: interview.jobName,
      respostas: interview.responses.length,
      inicio: interview.startTime,
      fim: new Date().toISOString()
    });
  }

  private async findCandidate(phone: string) {
    // Buscar candidatos do cliente ativo (1749849987543)
    console.log(`ğŸ” [DEBUG] Buscando candidatos para telefone: ${phone}`);
    const candidates = await storage.getCandidatesByClientId(1749849987543);
    return candidates.find(c => {
      if (!c.phone) return false;
      const candidatePhone = c.phone.replace(/\D/g, '');
      const searchPhone = phone.replace(/\D/g, '');
      return candidatePhone.includes(searchPhone) || searchPhone.includes(candidatePhone);
    });
  }

  private async sendMessage(to: string, message: string): Promise<void> {
    if (this.whatsappService) {
      await this.whatsappService.sendTextMessage(to, message);
    } else {
      console.log(`ğŸ“± Enviaria mensagem para ${to}: ${message}`);
    }
  }

  // MÃ©todos para debug
  getActiveInterviews(): Map<string, ActiveInterview> {
    return this.activeInterviews;
  }

  getInterviewStatus(phone: string): ActiveInterview | undefined {
    return this.activeInterviews.get(phone);
  }
}

export const simpleInterviewService = new SimpleInterviewService();