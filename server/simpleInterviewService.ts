import { storage } from './storage';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import FormData from 'form-data';

// Estado em memÃ³ria das entrevistas ativas
interface ActiveInterview {
  candidateId: string;
  candidateName: string;
  phone: string;
  jobId: string;
  jobName: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
}

class SimpleInterviewService {
  private activeInterviews: Map<string, ActiveInterview> = new Map();
  private openai: OpenAI;
  private whatsappService: any = null;

  constructor() {
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  }

  setWhatsAppService(service: any) {
    this.whatsappService = service;
  }

  async handleMessage(from: string, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nğŸ¯ [INTERVIEW] ===== NOVA MENSAGEM RECEBIDA =====`);
    console.log(`ğŸ“± [INTERVIEW] Telefone: ${phone}`);
    console.log(`ğŸ’¬ [INTERVIEW] Texto: "${text}"`);
    console.log(`ğŸµ [INTERVIEW] Ãudio: ${audioMessage ? 'SIM' : 'NÃƒO'}`);
    
    if (audioMessage) {
      console.log(`ğŸ§ [INTERVIEW] Dados do Ã¡udio:`, {
        type: audioMessage.type || 'nÃ£o informado',
        mimetype: audioMessage.mimetype || 'nÃ£o informado',
        size: audioMessage.fileLength || 'nÃ£o informado'
      });
    }

    // Verificar se hÃ¡ entrevista ativa
    const activeInterview = this.activeInterviews.get(phone);
    console.log(`ğŸ” [INTERVIEW] Entrevista ativa para ${phone}: ${activeInterview ? 'SIM' : 'NÃƒO'}`);
    
    if (activeInterview) {
      console.log(`ğŸ“Š [INTERVIEW] Status da entrevista:`, {
        candidato: activeInterview.candidateName,
        vaga: activeInterview.jobName,
        perguntaAtual: activeInterview.currentQuestion + 1,
        totalPerguntas: activeInterview.questions.length,
        respostasJaRecebidas: activeInterview.responses.length
      });
    }

    if (text === '1' && !activeInterview) {
      console.log(`ğŸš€ [INTERVIEW] Comando "1" detectado - iniciando entrevista`);
      await this.startInterview(phone);
    } else if (text === '2') {
      console.log(`âŒ [INTERVIEW] Comando "2" detectado - recusando entrevista`);
      await this.sendMessage(from, "Entendido. Obrigado!");
    } else if (text.toLowerCase() === 'parar' || text.toLowerCase() === 'sair') {
      console.log(`â¹ï¸ [INTERVIEW] Comando "parar/sair" detectado`);
      await this.stopInterview(phone);
    } else if (activeInterview) {
      console.log(`ğŸ“ [INTERVIEW] Processando resposta para pergunta ${activeInterview.currentQuestion + 1}`);
      await this.processResponse(from, activeInterview, text, audioMessage);
    } else {
      console.log(`â“ [INTERVIEW] Comando nÃ£o reconhecido - enviando instruÃ§Ãµes`);
      await this.sendMessage(from, "Digite:\n1 - Iniciar entrevista\n2 - NÃ£o participar");
    }
    
    console.log(`ğŸ¯ [INTERVIEW] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async startInterview(phone: string): Promise<void> {
    console.log(`ğŸš€ Iniciando entrevista para ${phone}`);

    // Buscar candidato
    const candidate = await this.findCandidate(phone);
    if (!candidate) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "âŒ Candidato nÃ£o encontrado.");
      return;
    }

    // Buscar vaga com perguntas
    try {
      const jobs = await storage.getJobs();
      
      const job = jobs.find(j => j.perguntas && j.perguntas.length > 0);
      
      if (!job) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "âŒ Nenhuma vaga disponÃ­vel no momento.");
        return;
      }
      
      console.log(`âœ… Vaga encontrada: ${job.nomeVaga} com ${job.perguntas.length} perguntas`);
      
      // Criar entrevista ativa
      const interview: ActiveInterview = {
        candidateId: candidate.id,
        candidateName: candidate.name,
        phone: phone,
        jobId: job.id,
        jobName: job.nomeVaga,
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString()
      };

      this.activeInterviews.set(phone, interview);

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `ğŸ¯ Entrevista iniciada para: ${job.nomeVaga}\nğŸ‘‹ OlÃ¡ ${candidate.name}!\nğŸ“ ${job.perguntas.length} perguntas\n\nâ³ Preparando primeira pergunta...`
      );

      // Enviar primeira pergunta
      await this.sendNextQuestion(phone, interview);
      
    } catch (error) {
      console.log(`âŒ Erro ao buscar vaga:`, error.message);
      await this.sendMessage(`${phone}@s.whatsapp.net`, "âŒ Erro ao carregar entrevista. Tente novamente.");
    }
  }

  private async sendNextQuestion(phone: string, interview: ActiveInterview): Promise<void> {
    const question = interview.questions[interview.currentQuestion];
    
    if (!question) {
      await this.finishInterview(phone, interview);
      return;
    }

    const questionNum = interview.currentQuestion + 1;
    const total = interview.questions.length;
    
    const message = `ğŸ“ Pergunta ${questionNum}/${total}:\n\n${question.pergunta}\n\nğŸ¤ Responda com Ã¡udio ou texto`;

    await this.sendMessage(`${phone}@s.whatsapp.net`, message);

    // Tentar enviar Ã¡udio TTS
    try {
      await this.sendQuestionAudio(phone, question.pergunta);
    } catch (error) {
      console.log(`âš ï¸ TTS falhou, pergunta enviada por texto`);
    }
  }

  private async sendQuestionAudio(phone: string, questionText: string): Promise<void> {
    try {
      const response = await this.openai.audio.speech.create({
        model: "tts-1",
        input: questionText,
        voice: "nova",
        response_format: "opus",
        speed: 1.0
      });

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer();
        
        if (this.whatsappService && this.whatsappService.socket) {
          await this.whatsappService.socket.sendMessage(`${phone}@s.whatsapp.net`, {
            audio: Buffer.from(audioBuffer),
            mimetype: 'audio/mp4',
            ptt: true
          });
          
          console.log(`ğŸµ Ãudio TTS enviado para ${phone}`);
        }
      }
    } catch (error) {
      console.log(`âŒ Erro TTS:`, error.message);
    }
  }

  private async processResponse(from: string, interview: ActiveInterview, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nğŸ¯ [AUDIO] ===== PROCESSANDO RESPOSTA =====`);
    console.log(`ğŸ“ [AUDIO] Telefone: ${phone}`);
    console.log(`ğŸ“ [AUDIO] Pergunta atual: ${interview.currentQuestion + 1}/${interview.questions.length}`);
    console.log(`ğŸ“ [AUDIO] Texto recebido: "${text}"`);
    console.log(`ğŸµ [AUDIO] Ãudio presente: ${audioMessage ? 'SIM' : 'NÃƒO'}`);

    let responseText = text;
    let audioFile: string | undefined;
    let audioSavedToDB = false;
    let transcriptionSavedToDB = false;

    // Se hÃ¡ Ã¡udio, processar
    if (audioMessage) {
      console.log(`ğŸ§ [AUDIO] Iniciando processamento de Ã¡udio...`);
      console.log(`ğŸ§ [AUDIO] Dados do Ã¡udio:`, {
        type: audioMessage.type,
        mimetype: audioMessage.mimetype,
        fileLength: audioMessage.fileLength,
        url: audioMessage.url ? 'presente' : 'nÃ£o presente'
      });
      
      try {
        console.log(`ğŸ”„ [AUDIO] Chamando transcribeAudio...`);
        const transcription = await this.transcribeAudio(audioMessage);
        
        if (transcription && transcription.length > 0) {
          responseText = transcription;
          audioFile = `audio_${phone}_${Date.now()}.ogg`;
          console.log(`âœ… [AUDIO] TranscriÃ§Ã£o bem-sucedida: "${responseText}"`);
          console.log(`ğŸ“ [AUDIO] Nome do arquivo de Ã¡udio: ${audioFile}`);
          
          // Salvar Ã¡udio localmente e no banco
          try {
            console.log(`ğŸ’¾ [AUDIO] Salvando Ã¡udio no sistema...`);
            const fs = require('fs');
            const tempAudioPath = `./uploads/${audioFile}`;
            fs.writeFileSync(tempAudioPath, audioBuffer);
            
            // Salvar referÃªncia no banco de dados
            const audioData = {
              id: Date.now(),
              candidatePhone: phone,
              filename: audioFile,
              filepath: tempAudioPath,
              size: audioBuffer.length,
              mimetype: audioMessage.mimetype || 'audio/ogg',
              timestamp: new Date().toISOString()
            };
            
            const storageModule = await import('./storage');
            const { doc, setDoc, collection } = await import('firebase/firestore');
            const db = storageModule.storage.db || storageModule.firebaseDb;
            await setDoc(doc(collection(db, 'audio_files'), audioData.id.toString()), audioData);
            
            audioSavedToDB = true;
            console.log(`âœ… [AUDIO] Ãudio salvo localmente: ${tempAudioPath}`);
            console.log(`âœ… [AUDIO] ReferÃªncia salva no banco: ${audioData.id}`);
          } catch (saveError) {
            console.log(`âŒ [AUDIO] Erro ao salvar Ã¡udio:`, saveError.message);
          }
          
        } else {
          console.log(`âš ï¸ [AUDIO] TranscriÃ§Ã£o vazia, usando texto: "${text}"`);
        }
      } catch (error) {
        console.log(`âŒ [AUDIO] Erro na transcriÃ§Ã£o:`, error.message);
        console.log(`âŒ [AUDIO] Stack trace:`, error.stack);
      }
    }

    // Salvar resposta na entrevista ativa
    const currentQuestion = interview.questions[interview.currentQuestion];
    const response = {
      questionId: interview.currentQuestion,
      questionText: currentQuestion.pergunta,
      responseText: responseText,
      audioFile: audioFile,
      timestamp: new Date().toISOString()
    };

    interview.responses.push(response);
    
    console.log(`ğŸ’¾ [AUDIO] Resposta salva na entrevista ativa:`, {
      pergunta: interview.currentQuestion + 1,
      respostaTexto: responseText.substring(0, 50) + (responseText.length > 50 ? '...' : ''),
      arquivoAudio: audioFile || 'nenhum',
      timestamp: response.timestamp
    });

    // Salvar transcriÃ§Ã£o no Firebase
    try {
      console.log(`ğŸ’¾ [AUDIO] Salvando transcriÃ§Ã£o no Firebase...`);
      const responseData = {
        id: Date.now(),
        candidatePhone: phone,
        candidateName: interview.candidateName,
        jobName: interview.jobName,
        questionId: interview.currentQuestion,
        questionText: currentQuestion.pergunta,
        responseText: responseText,
        audioFile: audioFile || null,
        timestamp: new Date().toISOString(),
        hasAudio: !!audioMessage,
        transcriptionSuccess: responseText.length > 0
      };
      
      // Salvar no Firebase Storage
      const { firebaseDb } = await import('./storage');
      const { doc, setDoc, collection } = await import('firebase/firestore');
      
      await setDoc(doc(collection(firebaseDb, 'interview_responses'), responseData.id.toString()), responseData);
      transcriptionSavedToDB = true;
      console.log(`âœ… [AUDIO] Resposta salva no Firebase:`, responseData.id);
    } catch (saveError) {
      console.log(`âŒ [AUDIO] Erro ao salvar no Firebase:`, saveError.message);
    }

    // AvanÃ§ar para prÃ³xima pergunta
    interview.currentQuestion++;
    this.activeInterviews.set(phone, interview);

    console.log(`ğŸ“Š [AUDIO] Status da entrevista atualizado:`, {
      proximaPergunta: interview.currentQuestion + 1,
      totalPerguntas: interview.questions.length,
      respostasColetadas: interview.responses.length,
      audioSalvoNoBanco: audioSavedToDB,
      transcricaoSalvaNoBanco: transcriptionSavedToDB
    });

    // Enviar confirmaÃ§Ã£o
    await this.sendMessage(from, `âœ… Resposta recebida! ${audioMessage ? 'ğŸµ Ãudio processado.' : ''} Preparando prÃ³xima pergunta...`);
    
    setTimeout(async () => {
      await this.sendNextQuestion(phone, interview);
    }, 2000);
    
    console.log(`ğŸ¯ [AUDIO] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async transcribeAudio(audioMessage: any): Promise<string> {
    console.log(`\nğŸ¯ [WHISPER] ===== INICIANDO TRANSCRIÃ‡ÃƒO =====`);
    
    try {
      // Baixar Ã¡udio via Baileys
      console.log(`â¬‡ï¸ [WHISPER] Baixando Ã¡udio do WhatsApp...`);
      console.log(`â¬‡ï¸ [WHISPER] Dados da mensagem de Ã¡udio:`, {
        type: audioMessage.type,
        mimetype: audioMessage.mimetype,
        fileLength: audioMessage.fileLength,
        url: audioMessage.url ? 'URL presente' : 'URL ausente'
      });
      
      // Baixar Ã¡udio usando o socket do WhatsApp
      let audioBuffer;
      try {
        if (this.whatsappService && this.whatsappService.socket) {
          console.log(`ğŸ”Œ [WHISPER] Usando socket ativo do WhatsApp service`);
          
          // Usar o socket diretamente para download
          const { downloadMediaMessage } = await import('@whiskeysockets/baileys');
          audioBuffer = await downloadMediaMessage(
            audioMessage,
            'buffer',
            {},
            {
              reuploadRequest: this.whatsappService.socket.updateMediaMessage
            }
          );
          console.log(`âœ… [WHISPER] Download realizado com socket - Tamanho: ${audioBuffer?.length || 0} bytes`);
        } else {
          throw new Error('Socket do WhatsApp nÃ£o disponÃ­vel');
        }
      } catch (downloadError) {
        console.log(`âŒ [WHISPER] Erro no download:`, downloadError.message);
        
        // Tentar mÃ©todo alternativo com dados da mensagem original
        try {
          console.log(`ğŸ”„ [WHISPER] Tentando mÃ©todo alternativo de download...`);
          const { downloadMediaMessage } = await import('@whiskeysockets/baileys');
          audioBuffer = await downloadMediaMessage(audioMessage, 'buffer');
          console.log(`âœ… [WHISPER] Download alternativo realizado - Tamanho: ${audioBuffer?.length || 0} bytes`);
        } catch (altError) {
          console.log(`âŒ [WHISPER] Download alternativo tambÃ©m falhou:`, altError.message);
          throw new Error(`Falha no download de Ã¡udio: ${downloadError.message}`);
        }
      }
      
      if (!audioBuffer || audioBuffer.length === 0) {
        console.log(`âŒ [WHISPER] Ãudio vazio ou invÃ¡lido`);
        throw new Error('Ãudio vazio apÃ³s download');
      }

      // Salvar temporariamente
      const tempFile = path.join('./uploads', `temp_${Date.now()}.ogg`);
      fs.writeFileSync(tempFile, audioBuffer);
      console.log(`ğŸ’¾ [WHISPER] Arquivo temporÃ¡rio salvo: ${tempFile}`);
      console.log(`ğŸ“Š [WHISPER] Tamanho do arquivo: ${fs.statSync(tempFile).size} bytes`);

      // Preparar FormData para OpenAI
      console.log(`ğŸ”„ [WHISPER] Preparando FormData para OpenAI Whisper...`);
      const formData = new FormData();
      formData.append('file', fs.createReadStream(tempFile));
      formData.append('model', 'whisper-1');
      formData.append('language', 'pt');
      
      console.log(`ğŸš€ [WHISPER] Enviando para OpenAI Whisper API...`);
      console.log(`ğŸ”‘ [WHISPER] API Key presente: ${process.env.OPENAI_API_KEY ? 'SIM' : 'NÃƒO'}`);

      const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          ...formData.getHeaders()
        },
        body: formData
      });

      console.log(`ğŸ“¡ [WHISPER] Response status: ${response.status}`);
      console.log(`ğŸ“¡ [WHISPER] Response ok: ${response.ok}`);

      if (!response.ok) {
        const errorText = await response.text();
        console.log(`âŒ [WHISPER] Erro da API OpenAI:`, errorText);
        throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      console.log(`ğŸ“ [WHISPER] Resultado completo da API:`, result);
      
      const transcription = result.text || '';
      console.log(`âœ… [WHISPER] TranscriÃ§Ã£o extraÃ­da: "${transcription}"`);
      console.log(`ğŸ“Š [WHISPER] Tamanho da transcriÃ§Ã£o: ${transcription.length} caracteres`);
      
      // Limpar arquivo temporÃ¡rio
      fs.unlinkSync(tempFile);
      console.log(`ğŸ—‘ï¸ [WHISPER] Arquivo temporÃ¡rio removido: ${tempFile}`);
      
      console.log(`ğŸ¯ [WHISPER] ===== TRANSCRIÃ‡ÃƒO CONCLUÃDA =====\n`);
      return transcription;
      
    } catch (error) {
      console.log(`âŒ [WHISPER] ERRO NA TRANSCRIÃ‡ÃƒO:`, error.message);
      console.log(`âŒ [WHISPER] Stack trace:`, error.stack);
      console.log(`ğŸ¯ [WHISPER] ===== TRANSCRIÃ‡ÃƒO FALHOU =====\n`);
      return '';
    }
  }

  private async finishInterview(phone: string, interview: ActiveInterview): Promise<void> {
    console.log(`ğŸ‰ Finalizando entrevista de ${interview.candidateName}`);

    // Salvar respostas no banco de dados
    try {
      await this.saveInterviewResults(interview);
      console.log(`ğŸ’¾ Entrevista salva no banco de dados`);
    } catch (error) {
      console.log(`âŒ Erro ao salvar:`, error.message);
    }

    // Mensagem final
    await this.sendMessage(`${phone}@s.whatsapp.net`, 
      `ğŸ‰ ParabÃ©ns ${interview.candidateName}!\n\nâœ… Entrevista concluÃ­da com sucesso!\nğŸ“Š ${interview.responses.length} respostas registradas\n\nObrigado pela participaÃ§Ã£o! Entraremos em contato em breve.`
    );

    // Remover da memÃ³ria
    this.activeInterviews.delete(phone);
  }

  private async stopInterview(phone: string): Promise<void> {
    const interview = this.activeInterviews.get(phone);
    if (interview) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, `â¹ï¸ Entrevista encerrada. Obrigado ${interview.candidateName}!`);
      this.activeInterviews.delete(phone);
    } else {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "Nenhuma entrevista ativa.");
    }
  }

  private async saveInterviewResults(interview: ActiveInterview): Promise<void> {
    // Implementar salvamento no Firebase/PostgreSQL se necessÃ¡rio
    // Por enquanto, apenas log
    console.log(`ğŸ“Š Resultados da entrevista:`, {
      candidato: interview.candidateName,
      vaga: interview.jobName,
      respostas: interview.responses.length,
      inicio: interview.startTime,
      fim: new Date().toISOString()
    });
  }

  private async findCandidate(phone: string) {
    // Buscar candidatos do cliente ativo (1749849987543)
    console.log(`ğŸ” [DEBUG] Buscando candidatos para telefone: ${phone}`);
    const candidates = await storage.getCandidatesByClientId(1749849987543);
    return candidates.find(c => {
      if (!c.phone) return false;
      const candidatePhone = c.phone.replace(/\D/g, '');
      const searchPhone = phone.replace(/\D/g, '');
      return candidatePhone.includes(searchPhone) || searchPhone.includes(candidatePhone);
    });
  }

  private async sendMessage(to: string, message: string): Promise<void> {
    if (this.whatsappService) {
      await this.whatsappService.sendTextMessage(to, message);
    } else {
      console.log(`ğŸ“± Enviaria mensagem para ${to}: ${message}`);
    }
  }

  // MÃ©todos para debug
  getActiveInterviews(): Map<string, ActiveInterview> {
    return this.activeInterviews;
  }

  getInterviewStatus(phone: string): ActiveInterview | undefined {
    return this.activeInterviews.get(phone);
  }
}

export const simpleInterviewService = new SimpleInterviewService();