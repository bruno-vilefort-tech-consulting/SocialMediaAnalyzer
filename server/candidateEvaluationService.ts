/**
 * Servi√ßo de Avalia√ß√£o de Candidatos usando OpenAI
 * 
 * Este arquivo implementa o sistema de pontua√ß√£o de respostas de candidatos
 * comparando com a resposta perfeita cadastrada pelo cliente.
 * 
 * Pontua√ß√£o de 0 a 100 baseada em:
 * - Conte√∫do e cobertura dos pontos-chave (70 pontos)
 * - Coer√™ncia e clareza (25 pontos) 
 * - Tom e profissionalismo (5 pontos)
 */

import OpenAI from 'openai';

interface EvaluationRequest {
  pergunta: string;
  respostaCandidato: string;
  respostaPerfeita: string;
}

interface EvaluationResult {
  pontuacaoGeral: number; // 0-100
  conteudo: number; // 0-70
  coerencia: number; // 0-25
  tom: number; // 0-5
  feedback?: string;
}

export class CandidateEvaluationService {
  private openai: OpenAI | null = null;

  async initialize(apiKey: string): Promise<void> {
    if (!apiKey) {
      throw new Error('OpenAI API Key √© obrigat√≥ria para avalia√ß√£o de candidatos');
    }
    
    this.openai = new OpenAI({ 
      apiKey: apiKey
    });
    
    console.log('‚úÖ [EVALUATION] Servi√ßo de avalia√ß√£o de candidatos inicializado');
  }

  async evaluateResponse(request: EvaluationRequest): Promise<EvaluationResult> {
    if (!this.openai) {
      throw new Error('Servi√ßo de avalia√ß√£o n√£o foi inicializado');
    }

    try {
      console.log('ü§ñ [EVALUATION] Iniciando avalia√ß√£o de resposta...');
      console.log('üìù [EVALUATION] Pergunta:', request.pergunta.substring(0, 50) + '...');
      console.log('üí≠ [EVALUATION] Resposta candidato:', request.respostaCandidato.substring(0, 50) + '...');
      console.log('‚≠ê [EVALUATION] Resposta perfeita:', request.respostaPerfeita.substring(0, 50) + '...');

      const prompt = this.buildEvaluationPrompt(request);
      
      const response = await this.openai.chat.completions.create({
        model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
        messages: [
          {
            role: "system",
            content: "Voc√™ √© um avaliador especialista de entrevistas de RH. Analise as respostas de forma objetiva e imparcial."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" },
        temperature: 0 // Temperatura zero para resultados completamente determin√≠sticos
      });

      const content = response.choices[0]?.message?.content;
      if (!content) {
        throw new Error('Resposta vazia da OpenAI');
      }

      console.log('üìä [EVALUATION] Resposta bruta da OpenAI:', content);
      
      const result = this.parseEvaluationResponse(content);
      
      console.log('‚úÖ [EVALUATION] Avalia√ß√£o conclu√≠da:', {
        pontuacaoGeral: result.pontuacaoGeral,
        conteudo: result.conteudo,
        coerencia: result.coerencia,
        tom: result.tom
      });

      return result;

    } catch (error) {
      console.error('‚ùå [EVALUATION] Erro na avalia√ß√£o:', error.message);
      
      // Fallback: retorna pontua√ß√£o neutra em caso de erro
      return this.getFallbackEvaluation();
    }
  }

  private buildEvaluationPrompt(request: EvaluationRequest): string {
    return `Compare a "Resposta do candidato" com a "Resposta perfeita".
Calcule uma pontua√ß√£o geral de 0 a 100 e notas parciais nos crit√©rios abaixo, usando apenas n√∫meros inteiros.

Crit√©rios e pesos (total 100):
1. Conte√∫do e cobertura dos pontos-chave ‚Äì 70
   ‚Ä¢ Verifique se o candidato aborda todos os temas essenciais, apresenta fatos corretos e demonstra entendimento completo da resposta perfeita.

2. Coer√™ncia e clareza ‚Äì 25
   ‚Ä¢ Avalie a l√≥gica da exposi√ß√£o, a organiza√ß√£o das ideias e a facilidade de compreens√£o, sem contradi√ß√µes ou ambiguidades.

3. Tom e profissionalismo ‚Äì 5
   ‚Ä¢ Observe a adequa√ß√£o da linguagem ao contexto da vaga, o respeito e a formalidade do discurso.

Formate a sa√≠da exatamente assim em JSON:
{
  "PONTUACAO_GERAL": <0-100>,
  "CONTEUDO": <0-70>,
  "COERENCIA": <0-25>,
  "TOM": <0-5>,
  "FEEDBACK": "Breve an√°lise da resposta (opcional)"
}

### Pergunta
${request.pergunta}

### Resposta perfeita
${request.respostaPerfeita}

### Resposta do candidato
${request.respostaCandidato}`;
  }

  private parseEvaluationResponse(content: string): EvaluationResult {
    try {
      const parsed = JSON.parse(content);
      
      // Validar e normalizar as pontua√ß√µes
      const pontuacaoGeral = this.validateScore(parsed.PONTUACAO_GERAL || 0, 0, 100);
      const conteudo = this.validateScore(parsed.CONTEUDO || 0, 0, 70);
      const coerencia = this.validateScore(parsed.COERENCIA || 0, 0, 25);
      const tom = this.validateScore(parsed.TOM || 0, 0, 5);

      return {
        pontuacaoGeral,
        conteudo,
        coerencia,
        tom,
        feedback: parsed.FEEDBACK || ''
      };

    } catch (parseError) {
      console.error('‚ùå [EVALUATION] Erro ao parsear resposta JSON:', parseError.message);
      console.error('üìÑ [EVALUATION] Conte√∫do recebido:', content);
      
      return this.getFallbackEvaluation();
    }
  }

  private validateScore(score: any, min: number, max: number): number {
    const numScore = parseInt(score);
    if (isNaN(numScore)) return min;
    return Math.max(min, Math.min(max, numScore));
  }

  private getFallbackEvaluation(): EvaluationResult {
    console.log('‚ö†Ô∏è [EVALUATION] Usando avalia√ß√£o fallback');
    return {
      pontuacaoGeral: 50,
      conteudo: 35,
      coerencia: 12,
      tom: 3,
      feedback: 'Avalia√ß√£o autom√°tica indispon√≠vel'
    };
  }

  /**
   * Processa avalia√ß√£o de uma resposta individual durante a entrevista
   */
  async evaluateInterviewResponse(
    interviewId: string,
    questionText: string,
    candidateResponse: string,
    perfectAnswer: string,
    openaiApiKey: string
  ): Promise<number> {
    try {
      // Inicializar servi√ßo se necess√°rio
      if (!this.openai) {
        await this.initialize(openaiApiKey);
      }

      const evaluation = await this.evaluateResponse({
        pergunta: questionText,
        respostaCandidato: candidateResponse,
        respostaPerfeita: perfectAnswer
      });

      console.log(`üìä [EVALUATION] Entrevista ${interviewId} - Pontua√ß√£o: ${evaluation.pontuacaoGeral}/100`);
      
      return evaluation.pontuacaoGeral;

    } catch (error) {
      console.error(`‚ùå [EVALUATION] Erro na avalia√ß√£o da entrevista ${interviewId}:`, error.message);
      return 50; // Pontua√ß√£o neutra em caso de erro
    }
  }
}

// Inst√¢ncia singleton do servi√ßo
export const candidateEvaluationService = new CandidateEvaluationService();