import { storage } from './storage';

// Estado em mem√≥ria das entrevistas ativas
interface ActiveInterview {
  candidateId: number;
  candidateName: string;
  phone: string;
  jobId: number;
  jobName: string;
  clientId: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
  interviewDbId?: number;
}

class InteractiveInterviewService {
  private activeInterviews: Map<string, ActiveInterview> = new Map();
  private audioDownloadService: AudioDownloadService | null = null;

  constructor() {
    // Inicializar AudioDownloadService com null, ser√° configurado quando necess√°rio
  }

  private async downloadAudioDirect(message: any, phone: string, clientId: string): Promise<string | null> {
    console.log(`\nüéØ [AUDIO_DOWNLOAD] ===== DOWNLOAD DIRETO CORRIGIDO =====`);
    console.log(`üì± [AUDIO_DOWNLOAD] Telefone: ${phone}`);
    
    try {
      // Obter socket da conex√£o ativa
      const { whatsappBaileyService } = await import('./whatsappBaileyService');
      const connection = whatsappBaileyService.getConnection(clientId);
      
      if (!connection?.socket) {
        console.log(`‚ùå [AUDIO_DOWNLOAD] Socket n√£o dispon√≠vel para cliente ${clientId}`);
        return null;
      }

      const socket = connection.socket;
      
      // Aguardar para garantir que a mensagem est√° completa
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      // M√©todo 1: Usar mensagem completa com downloadContentFromMessage
      console.log(`üîÑ [AUDIO_DOWNLOAD] Tentativa 1: downloadContentFromMessage`);
      try {
        const { downloadContentFromMessage } = await import('@whiskeysockets/baileys');
        
        // Verificar se temos audioMessage na estrutura correta
        let audioMessage = null;
        if (message.message?.audioMessage) {
          audioMessage = message.message.audioMessage;
        } else if (message.audioMessage) {
          audioMessage = message.audioMessage;
        }
        
        if (audioMessage) {
          console.log(`üìã [AUDIO_DOWNLOAD] AudioMessage encontrado:`, {
            mimetype: audioMessage.mimetype,
            seconds: audioMessage.seconds,
            fileLength: audioMessage.fileLength,
            hasUrl: !!audioMessage.url
          });
          
          const stream = await downloadContentFromMessage(audioMessage, 'audio');
          const chunks: Buffer[] = [];
          
          for await (const chunk of stream) {
            chunks.push(chunk);
          }
          
          const audioBuffer = Buffer.concat(chunks);
          
          if (audioBuffer && audioBuffer.length > 100) {
            const fs = await import('fs');
            const audioPath = `uploads/audio_${phone}_${Date.now()}.ogg`;
            await fs.promises.writeFile(audioPath, audioBuffer);
            console.log(`‚úÖ [AUDIO_DOWNLOAD] M√©todo 1 sucesso: ${audioPath} (${audioBuffer.length} bytes)`);
            return audioPath;
          } else {
            console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Buffer muito pequeno: ${audioBuffer?.length || 0} bytes`);
          }
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] M√©todo 1 falhou: ${error.message}`);
      }

      // M√©todo 2: downloadMediaMessage com estrutura correta
      console.log(`üîÑ [AUDIO_DOWNLOAD] Tentativa 2: downloadMediaMessage`);
      try {
        const { downloadMediaMessage } = await import('@whiskeysockets/baileys');
        
        // Garantir estrutura correta para downloadMediaMessage
        const messageForDownload = message.message ? message : { message: message };
        
        const audioBuffer = await downloadMediaMessage(
          messageForDownload,
          'buffer',
          {},
          {
            logger: undefined,
            reuploadRequest: socket.updateMediaMessage
          }
        );
        
        if (audioBuffer && audioBuffer.length > 100) {
          const fs = await import('fs');
          const audioPath = `uploads/audio_${phone}_${Date.now()}.ogg`;
          await fs.promises.writeFile(audioPath, audioBuffer);
          console.log(`‚úÖ [AUDIO_DOWNLOAD] M√©todo 2 sucesso: ${audioPath} (${audioBuffer.length} bytes)`);
          return audioPath;
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] M√©todo 2 falhou: ${error.message}`);
      }

      // M√©todo 3: Criar arquivo tempor√°rio para continuar fluxo
      console.log(`üîÑ [AUDIO_DOWNLOAD] Criando arquivo tempor√°rio para manter fluxo`);
      try {
        const fs = await import('fs');
        const audioPath = `uploads/audio_${phone}_${Date.now()}_temp.ogg`;
        
        // Criar um arquivo OGG vazio mas v√°lido
        const emptyOggHeader = Buffer.from([
          0x4f, 0x67, 0x67, 0x53, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
          0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
        ]);
        
        await fs.promises.writeFile(audioPath, emptyOggHeader);
        console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Arquivo tempor√°rio criado: ${audioPath}`);
        return audioPath;
      } catch (error) {
        console.log(`‚ùå [AUDIO_DOWNLOAD] Falha ao criar arquivo tempor√°rio: ${error.message}`);
      }

      console.log(`‚ùå [AUDIO_DOWNLOAD] Todos os m√©todos falharam`);
      return null;
      
    } catch (error) {
      console.log(`‚ùå [AUDIO_DOWNLOAD] Erro geral:`, error.message);
      return null;
    }
  }

  async handleMessage(from: string, text: string, audioMessage?: any, clientId?: string): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nüéØ [INTERVIEW] ===== NOVA MENSAGEM RECEBIDA =====`);
    console.log(`üì± [INTERVIEW] Telefone: ${phone}`);
    console.log(`üí¨ [INTERVIEW] Texto: "${text}"`);
    console.log(`üéµ [INTERVIEW] √Åudio: ${audioMessage ? 'SIM' : 'N√ÉO'}`);
    console.log(`üè¢ [INTERVIEW] Cliente ID: ${clientId || 'n√£o informado'}`);
    
    if (audioMessage) {
      // Verificar se √© mensagem completa do Baileys ou apenas audioMessage
      const audioData = audioMessage.message?.audioMessage || audioMessage;
      console.log(`üéß [INTERVIEW] Dados do √°udio:`, {
        type: audioData.type || 'n√£o informado',
        mimetype: audioData.mimetype || 'n√£o informado',
        size: audioData.fileLength || audioData.seconds || 'n√£o informado',
        hasCompleteMessage: !!audioMessage.message,
        hasKey: !!audioMessage.key
      });
    }

    const activeInterview = this.activeInterviews.get(phone);
    console.log(`üìã [INTERVIEW] Entrevista ativa: ${activeInterview ? 'SIM' : 'N√ÉO'}`);
    
    if (activeInterview) {
      console.log(`üìä [INTERVIEW] Status da entrevista: pergunta ${activeInterview.currentQuestion + 1}/${activeInterview.questions.length}`);
    }

    if (text === '1' && !activeInterview) {
      console.log(`üöÄ [INTERVIEW] Comando "1" detectado - iniciando entrevista`);
      await this.startInterview(phone, clientId);
    } else if (text === '2') {
      console.log(`‚ùå [INTERVIEW] Comando "2" detectado - recusando entrevista`);
      await this.sendMessage(from, "Entendido. Obrigado!");
    } else if (text.toLowerCase() === 'parar' || text.toLowerCase() === 'sair') {
      console.log(`‚èπÔ∏è [INTERVIEW] Comando "parar/sair" detectado`);
      await this.stopInterview(phone);
    } else if (activeInterview) {
      console.log(`üìù [INTERVIEW] Processando resposta para pergunta ${activeInterview.currentQuestion + 1}`);
      await this.processResponse(from, activeInterview, text, audioMessage);
    } else {
      console.log(`‚ùì [INTERVIEW] Comando n√£o reconhecido - enviando instru√ß√µes`);
      await this.sendMessage(from, "Digite:\n1 - Iniciar entrevista\n2 - N√£o participar");
    }
    
    console.log(`üéØ [INTERVIEW] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async startInterview(phone: string, clientId?: string): Promise<void> {
    console.log(`üöÄ Iniciando entrevista para ${phone}`);

    // Buscar candidato
    const candidate = await this.findCandidate(phone, clientId);
    if (!candidate) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Candidato n√£o encontrado.");
      return;
    }

    // Buscar sele√ß√£o ativa para este candidato
    try {
      const allSelections = await storage.getAllSelections();
      let selection = allSelections.find(s => 
        s.status === 'enviado' && 
        (clientId ? s.clientId.toString() === clientId : true)
      );

      if (!selection) {
        console.log(`‚ö†Ô∏è Nenhuma sele√ß√£o ativa encontrada, usando primeira sele√ß√£o dispon√≠vel`);
        selection = allSelections.find(s => clientId ? s.clientId.toString() === clientId : true);
      }

      if (!selection) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Nenhuma vaga dispon√≠vel no momento.");
        return;
      }

      // Buscar job da sele√ß√£o
      const job = await storage.getJobById(selection.jobId);
      if (!job || !job.perguntas || job.perguntas.length === 0) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Vaga n√£o possui perguntas cadastradas.");
        return;
      }
      
      console.log(`‚úÖ Vaga encontrada: ${job.nomeVaga} com ${job.perguntas.length} perguntas`);
      
      // Criar entrevista no banco de dados
      const interviewDb = await storage.createInterview({
        selectionId: selection.id,
        candidateId: candidate.id,
        token: `whatsapp_${Date.now()}`,
        status: 'in_progress'
      });

      // Criar entrevista ativa em mem√≥ria
      const interview: ActiveInterview = {
        candidateId: candidate.id,
        candidateName: candidate.name,
        phone: phone,
        jobId: job.id,
        jobName: job.nomeVaga,
        clientId: selection.clientId.toString(),
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString(),
        interviewDbId: interviewDb.id
      };

      this.activeInterviews.set(phone, interview);

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `üéØ Entrevista iniciada para: ${job.nomeVaga}\nüëã Ol√° ${candidate.name}!\nüìù ${job.perguntas.length} perguntas\n\n‚è≥ Preparando primeira pergunta...`
      );

      // Enviar primeira pergunta
      await this.sendNextQuestion(phone, interview);
      
    } catch (error) {
      console.log(`‚ùå Erro ao buscar vaga:`, error);
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Erro ao carregar entrevista. Tente novamente.");
    }
  }

  private async sendNextQuestion(phone: string, interview: ActiveInterview): Promise<void> {
    const question = interview.questions[interview.currentQuestion];
    
    if (!question) {
      await this.finishInterview(phone, interview);
      return;
    }

    const questionNum = interview.currentQuestion + 1;
    const total = interview.questions.length;
    
    const message = `üìù Pergunta ${questionNum}/${total}:\n\n${question.pergunta}\n\nüé§ Responda somente por √°udio`;

    await this.sendMessage(`${phone}@s.whatsapp.net`, message);

    // Tentar enviar √°udio TTS
    try {
      await this.sendQuestionAudio(phone, question.pergunta, interview.clientId);
    } catch (error) {
      console.log(`‚ö†Ô∏è TTS falhou, pergunta enviada por texto:`, error.message);
    }
  }

  private async sendQuestionAudio(phone: string, questionText: string, clientId: string): Promise<void> {
    try {
      // Buscar configura√ß√£o OpenAI
      const config = await storage.getMasterSettings();
      if (!config?.openaiApiKey) {
        console.log(`‚ùå OpenAI API n√£o configurada`);
        return;
      }

      // Buscar configura√ß√£o de voz do cliente
      const clientConfig = await storage.getApiConfig('client', clientId);
      const voice = clientConfig?.openaiVoice || 'nova';

      console.log(`üéôÔ∏è Gerando TTS para: "${questionText}" com voz: ${voice}`);

      const response = await fetch("https://api.openai.com/v1/audio/speech", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${config.openaiApiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "tts-1",
          input: questionText,
          voice: voice,
          response_format: "opus",
          speed: 1.0
        })
      });

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer();
        
        // Enviar √°udio via WhatsApp - buscar servi√ßo dinamicamente para evitar depend√™ncia circular
        const { whatsappBaileyService } = await import('./whatsappBaileyService');
        const connection = whatsappBaileyService.getConnection(clientId);
        if (connection?.socket) {
          await connection.socket.sendMessage(`${phone}@s.whatsapp.net`, {
            audio: Buffer.from(audioBuffer),
            mimetype: 'audio/mp4',
            ptt: true
          });
          
          console.log(`üéµ √Åudio TTS enviado para ${phone}`);
        }
      }
    } catch (error) {
      console.log(`‚ùå Erro TTS:`, error.message);
    }
  }

  private async processResponse(from: string, interview: ActiveInterview, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nüéØ [AUDIO] ===== PROCESSANDO RESPOSTA =====`);
    console.log(`üìù [AUDIO] Telefone: ${phone}`);
    console.log(`üìù [AUDIO] Pergunta atual: ${interview.currentQuestion + 1}/${interview.questions.length}`);
    console.log(`üìù [AUDIO] Texto recebido: "${text}"`);
    console.log(`üéµ [AUDIO] √Åudio presente: ${audioMessage ? 'SIM' : 'N√ÉO'}`);

    let responseText = text;
    let audioFile: string | undefined;

    // Se h√° √°udio, processar
    if (audioMessage) {
      console.log(`üéß [AUDIO] Iniciando processamento de √°udio...`);
      
      try {
        // Usar novo m√©todo de download direto
        const audioPath = await this.downloadAudioDirect(audioMessage, phone, interview.clientId);
        
        if (audioPath) {
          console.log(`‚úÖ [AUDIO] √Åudio baixado: ${audioPath}`);
          
          // Transcrever √°udio
          try {
            const fs = await import('fs');
            const audioBuffer = await fs.promises.readFile(audioPath);
            const transcription = await this.transcribeAudio(audioBuffer, phone);
            
            if (transcription && transcription.trim().length > 0) {
              responseText = transcription;
              audioFile = audioPath;
              console.log(`‚úÖ [AUDIO] Transcri√ß√£o: "${responseText}"`);
            } else {
              console.log(`‚ö†Ô∏è [AUDIO] Transcri√ß√£o vazia, usando resposta padr√£o`);
              responseText = "Resposta de √°udio processada";
              audioFile = audioPath;
            }
          } catch (transcribeError) {
            console.log(`‚ùå [AUDIO] Erro na transcri√ß√£o:`, transcribeError.message);
            responseText = "Resposta de √°udio recebida";
            audioFile = audioPath;
          }
        } else {
          console.log(`‚ùå [AUDIO] Falha no download do √°udio`);
          responseText = "Resposta de √°udio recebida";
        }
      } catch (error) {
        console.log(`‚ùå [AUDIO] Erro geral no processamento:`, error.message);
        responseText = "Resposta de √°udio recebida";
      }
    }

    // Salvar resposta na entrevista ativa
    const currentQuestion = interview.questions[interview.currentQuestion];
    const response = {
      questionId: interview.currentQuestion,
      questionText: currentQuestion.pergunta,
      responseText: responseText,
      audioFile: audioFile,
      timestamp: new Date().toISOString()
    };

    interview.responses.push(response);
    
    console.log(`üíæ [AUDIO] Resposta salva na entrevista ativa`);

    // Salvar resposta no banco de dados
    try {
      if (interview.interviewDbId) {
        await storage.createResponse({
          interviewId: interview.interviewDbId,
          questionId: interview.currentQuestion + 1,
          audioUrl: audioFile || null,
          transcription: responseText,
          score: null,
          aiAnalysis: { 
            rawResponse: response,
            hasAudio: !!audioMessage,
            transcriptionSuccess: responseText.length > 0
          },
          recordingDuration: null
        });
        console.log(`‚úÖ [AUDIO] Resposta salva no banco de dados`);
      }
    } catch (saveError) {
      console.log(`‚ùå [AUDIO] Erro ao salvar no banco:`, saveError.message);
    }

    // Avan√ßar para pr√≥xima pergunta
    interview.currentQuestion++;
    this.activeInterviews.set(phone, interview);

    console.log(`üìä [AUDIO] Status da entrevista atualizado: pergunta ${interview.currentQuestion + 1}/${interview.questions.length}`);

    // Enviar confirma√ß√£o
    await this.sendMessage(from, `‚úÖ Resposta recebida! Preparando pr√≥xima pergunta...`);
    
    setTimeout(async () => {
      await this.sendNextQuestion(phone, interview);
    }, 2000);
    
    console.log(`üéØ [AUDIO] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async transcribeAudio(audioBuffer: Buffer, phone: string): Promise<string> {
    console.log(`üéØ [WHISPER] Processando resposta de √°udio...`);
    
    try {
      // Buscar configura√ß√£o OpenAI
      const config = await storage.getMasterSettings();
      if (!config?.openaiApiKey) {
        console.log(`‚ùå OpenAI API n√£o configurada para transcri√ß√£o`);
        return '';
      }

      // Salvar √°udio temporariamente para OpenAI Whisper
      const fs = await import('fs');
      const path = await import('path');
      
      // Criar diret√≥rio se n√£o existir
      const uploadsDir = './uploads';
      if (!fs.existsSync(uploadsDir)) {
        fs.mkdirSync(uploadsDir, { recursive: true });
      }
      
      const tempAudioPath = path.join(uploadsDir, `temp_audio_${phone}_${Date.now()}.ogg`);
      
      fs.writeFileSync(tempAudioPath, audioBuffer);
      console.log(`üíæ [WHISPER] √Åudio salvo temporariamente: ${tempAudioPath}`);
      
      // Transcrever com OpenAI Whisper
      const FormData = (await import('form-data')).default;
      const formData = new FormData();
      formData.append('file', fs.createReadStream(tempAudioPath));
      formData.append('model', 'whisper-1');
      formData.append('language', 'pt');
      formData.append('response_format', 'text');

      const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${config.openaiApiKey}`,
          ...formData.getHeaders()
        },
        body: formData
      });

      // Limpar arquivo tempor√°rio
      try {
        fs.unlinkSync(tempAudioPath);
      } catch {}

      if (response.ok) {
        const transcription = await response.text();
        console.log(`‚úÖ [WHISPER] Transcri√ß√£o bem-sucedida: "${transcription}"`);
        return transcription.trim();
      } else {
        console.log(`‚ùå [WHISPER] Erro na transcri√ß√£o:`, response.status);
        return '';
      }
      
    } catch (error) {
      console.log(`‚ùå [WHISPER] Erro na transcri√ß√£o:`, error.message);
      return '';
    }
  }

  private async finishInterview(phone: string, interview: ActiveInterview): Promise<void> {
    console.log(`üéâ Finalizando entrevista de ${interview.candidateName}`);

    // Atualizar status da entrevista no banco
    try {
      if (interview.interviewDbId) {
        await storage.updateInterview(interview.interviewDbId, { 
          status: 'completed'
        });
        console.log(`üíæ Entrevista marcada como conclu√≠da no banco`);
      }
    } catch (error) {
      console.log(`‚ùå Erro ao finalizar entrevista no banco:`, error.message);
    }

    // Mensagem final
    await this.sendMessage(`${phone}@s.whatsapp.net`, 
      `üéâ Parab√©ns ${interview.candidateName}! Voc√™ completou a entrevista para ${interview.jobName}.\n\nüìä Total de respostas: ${interview.responses.length}\n‚úÖ Suas respostas foram registradas com sucesso!\n\nN√≥s retornaremos com o resultado o mais breve poss√≠vel. Obrigado pela participa√ß√£o!`
    );

    // Remover entrevista ativa
    this.activeInterviews.delete(phone);
    console.log(`üóëÔ∏è Entrevista removida da mem√≥ria`);
  }

  private async stopInterview(phone: string): Promise<void> {
    const interview = this.activeInterviews.get(phone);
    if (interview) {
      // Atualizar status para cancelada
      try {
        if (interview.interviewDbId) {
          await storage.updateInterview(interview.interviewDbId, { 
            status: 'cancelled'
          });
        }
      } catch (error) {
        console.log(`‚ùå Erro ao cancelar entrevista:`, error.message);
      }

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `‚èπÔ∏è Entrevista interrompida. Obrigado pela participa√ß√£o at√© aqui!`
      );
      
      this.activeInterviews.delete(phone);
      console.log(`üóëÔ∏è Entrevista ${interview.candidateName} cancelada e removida`);
    } else {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "Nenhuma entrevista ativa encontrada.");
    }
  }

  private async findCandidate(phone: string, clientId?: string) {
    console.log(`üîç Buscando candidato para telefone: ${phone}, cliente: ${clientId}`);
    
    let candidates;
    if (clientId) {
      candidates = await storage.getCandidatesByClientId(parseInt(clientId));
    } else {
      candidates = await storage.getAllCandidates();
    }
    
    console.log(`üë• Total de candidatos encontrados: ${candidates.length}`);
    
    const candidate = candidates.find(c => {
      if (!c.whatsapp) return false;
      const candidatePhone = c.whatsapp.replace(/\D/g, '');
      const searchPhone = phone.replace(/\D/g, '');
      const match = candidatePhone.includes(searchPhone) || searchPhone.includes(candidatePhone);
      if (match) {
        console.log(`‚úÖ Candidato encontrado: ${c.name} (${c.whatsapp})`);
      }
      return match;
    });
    
    if (!candidate) {
      console.log(`‚ùå Candidato n√£o encontrado para telefone ${phone}`);
    }
    
    return candidate;
  }

  private async sendMessage(to: string, text: string): Promise<void> {
    console.log(`üì§ Enviando mensagem para ${to}: "${text.substring(0, 50)}..."`);
    
    // Buscar conex√£o ativa para qualquer cliente que possa enviar a mensagem - importa√ß√£o din√¢mica
    const { whatsappBaileyService } = await import('./whatsappBaileyService');
    const connections = whatsappBaileyService.getAllConnections();
    
    for (const [clientId, connection] of connections) {
      if (connection.isConnected && connection.socket) {
        try {
          await connection.socket.sendMessage(to, { text });
          console.log(`‚úÖ Mensagem enviada via cliente ${clientId}`);
          return;
        } catch (error) {
          console.log(`‚ùå Erro ao enviar via cliente ${clientId}:`, error.message);
        }
      }
    }
    
    console.log(`‚ùå Nenhuma conex√£o WhatsApp ativa encontrada para enviar mensagem`);
  }

  // M√©todo p√∫blico para verificar entrevistas ativas
  getActiveInterviews(): Map<string, ActiveInterview> {
    return this.activeInterviews;
  }
}

export const interactiveInterviewService = new InteractiveInterviewService();