import { storage } from './storage';
import { userIsolatedRoundRobin } from '../whatsapp/services/userIsolatedRoundRobin';
import { isValidAudio, isValidAudioBuffer, MIN_AUDIO_SIZE, MAX_AUDIO_SIZE } from './utils/audio';

// üéØ ETAPA 1: AN√ÅLISE E MAPEAMENTO DO FLUXO ATUAL
// Arquivos que alteram estado da entrevista:
// - interactiveInterviewService.ts: Gerencia activeInterviews Map, processa respostas, avan√ßa perguntas
// - simpleMultiBailey.ts: Recebe mensagens WhatsApp e direciona para handleMessage
// - userIsolatedRoundRobin.ts: Controla cad√™ncia de mensagens round-robin

// üèóÔ∏è ETAPA 2: ESTRUTURA CENTRALIZADA DE ESTADO DA SESS√ÉO
interface QueuedResponse {
  id: string;
  phone: string;
  text: string;
  audioMessage?: any;
  timestamp: number;
  processed: boolean;
}

// Legacy ActiveInterview para compatibilidade
interface ActiveInterview {
  candidateId: number;
  candidateName: string;
  phone: string;
  jobId: number;
  jobName: string;
  clientId: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
  selectionId: string;
  interviewDbId?: string;
}

interface InterviewSession {
  // Estado da entrevista
  candidateId: number;
  candidateName: string;
  phone: string;
  jobId: number;
  jobName: string;
  clientId: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
  selectionId: string;
  interviewDbId?: string;
  
  // üîí ETAPA 3: CONTROLE DE CONCORR√äNCIA
  responseQueue: QueuedResponse[];
  isProcessing: boolean;
  lock: boolean;
  lastActivity: number;
  
  // üìä ETAPA 5: MONITORAMENTO
  totalResponses: number;
  queuePeakSize: number;
  processingTimeMs: number[];
}

// üîÑ ETAPA 4: GERENCIADOR DE FILA E MUTEX
class ResponseQueueManager {
  private queues: Map<string, QueuedResponse[]> = new Map();
  private locks: Map<string, boolean> = new Map();
  private processing: Map<string, boolean> = new Map();
  
  // Adicionar resposta √† fila
  enqueue(phone: string, response: QueuedResponse): void {
    if (!this.queues.has(phone)) {
      this.queues.set(phone, []);
    }
    this.queues.get(phone)!.push(response);
    console.log(`üìù [QUEUE] Resposta adicionada √† fila ${phone}: ${this.queues.get(phone)!.length} total`);
  }
  
  // Processar pr√≥xima resposta da fila (com lock)
  async dequeue(phone: string): Promise<QueuedResponse | null> {
    // Verificar se j√° est√° processando
    if (this.processing.get(phone) || this.locks.get(phone)) {
      console.log(`üîí [QUEUE] Sess√£o ${phone} bloqueada, aguardando...`);
      return null;
    }
    
    const queue = this.queues.get(phone);
    if (!queue || queue.length === 0) {
      return null;
    }
    
    // Aplicar lock
    this.locks.set(phone, true);
    this.processing.set(phone, true);
    
    const response = queue.shift()!;
    console.log(`üîì [QUEUE] Processando resposta ${response.id} para ${phone}: ${queue.length} restantes`);
    return response;
  }
  
  // Liberar lock ap√≥s processamento
  unlock(phone: string): void {
    this.locks.set(phone, false);
    this.processing.set(phone, false);
    console.log(`‚úÖ [QUEUE] Lock liberado para ${phone}`);
  }
  
  // Obter status da fila
  getQueueStatus(phone: string): { size: number; isLocked: boolean; isProcessing: boolean } {
    return {
      size: this.queues.get(phone)?.length || 0,
      isLocked: this.locks.get(phone) || false,
      isProcessing: this.processing.get(phone) || false
    };
  }
  
  // Limpar fila antiga
  clearStaleQueue(phone: string): void {
    this.queues.delete(phone);
    this.locks.delete(phone);
    this.processing.delete(phone);
    console.log(`üßπ [QUEUE] Fila limpa para ${phone}`);
  }
}

class InteractiveInterviewService {
  private activeSessions: Map<string, InterviewSession> = new Map();
  private queueManager: ResponseQueueManager = new ResponseQueueManager();
  
  // Legacy support para c√≥digo existente
  private get activeInterviews(): Map<string, any> {
    const legacyMap = new Map();
    this.activeSessions.forEach((session, phone) => {
      legacyMap.set(phone, {
        candidateId: session.candidateId,
        candidateName: session.candidateName,
        phone: session.phone,
        jobId: session.jobId,
        jobName: session.jobName,
        clientId: session.clientId,
        currentQuestion: session.currentQuestion,
        questions: session.questions,
        responses: session.responses,
        startTime: session.startTime,
        selectionId: session.selectionId,
        interviewDbId: session.interviewDbId
      });
    });
    return legacyMap;
  }
  
  // üîí PROTE√á√ÉO CONTRA CONCORR√äNCIA: Evitar processamento simult√¢neo (LEGACY)
  private processingRequests: Set<string> = new Set(); // phone_action para evitar duplicatas

  constructor() {
    // üîÑ ETAPA 5: MONITORAMENTO - Limpeza peri√≥dica de filas antigas
    this.startQueueMonitoring();
  }

  // üìä ETAPA 5: SISTEMA DE MONITORAMENTO E ALERTAS
  private startQueueMonitoring(): void {
    setInterval(() => {
      this.monitorQueuePerformance();
    }, 30000); // Monitorar a cada 30 segundos
  }

  private monitorQueuePerformance(): void {
    const now = Date.now();
    const stats = {
      activeSessions: this.activeSessions.size,
      totalQueues: 0,
      maxQueueSize: 0,
      avgProcessingTime: 0,
      staleQueues: 0
    };

    // Analisar performance das sess√µes ativas
    this.activeSessions.forEach((session, phone) => {
      const queueStatus = this.queueManager.getQueueStatus(phone);
      stats.totalQueues++;
      
      if (queueStatus.size > stats.maxQueueSize) {
        stats.maxQueueSize = queueStatus.size;
      }

      // Alertar sobre filas grandes (poss√≠vel gargalo)
      if (queueStatus.size > 5) {
        console.warn(`‚ö†Ô∏è [MONITOR] Fila grande detectada para ${phone}: ${queueStatus.size} respostas pendentes`);
      }

      // Calcular tempo m√©dio de processamento
      if (session.processingTimeMs.length > 0) {
        const avgTime = session.processingTimeMs.reduce((a, b) => a + b) / session.processingTimeMs.length;
        stats.avgProcessingTime += avgTime;
      }

      // Detectar sess√µes inativas (mais de 30 minutos sem atividade)
      if (now - session.lastActivity > 30 * 60 * 1000) {
        stats.staleQueues++;
        console.log(`üßπ [MONITOR] Sess√£o inativa detectada: ${phone} (${Math.round((now - session.lastActivity) / 60000)} min atr√°s)`);
        
        // Limpar sess√£o antiga
        this.queueManager.clearStaleQueue(phone);
        this.activeSessions.delete(phone);
      }
    });

    stats.avgProcessingTime = stats.totalQueues > 0 ? stats.avgProcessingTime / stats.totalQueues : 0;

    // Log de estat√≠sticas peri√≥dicas
    if (stats.activeSessions > 0) {
      console.log(`üìä [MONITOR] Estat√≠sticas do sistema:`, {
        ...stats,
        avgProcessingTime: `${Math.round(stats.avgProcessingTime)}ms`
      });
    }
  }

  // üìä M√âTODO P√öBLICO PARA OBTER M√âTRICAS DO SISTEMA
  public getSystemMetrics(): any {
    const metrics = {
      activeSessions: this.activeSessions.size,
      queues: new Map(),
      totalProcessingTime: 0,
      totalResponses: 0
    };

    this.activeSessions.forEach((session, phone) => {
      const queueStatus = this.queueManager.getQueueStatus(phone);
      metrics.queues.set(phone, {
        queueSize: queueStatus.size,
        isProcessing: queueStatus.isProcessing,
        totalResponses: session.totalResponses,
        avgProcessingTime: session.processingTimeMs.length > 0 
          ? session.processingTimeMs.reduce((a, b) => a + b) / session.processingTimeMs.length 
          : 0,
        lastActivity: session.lastActivity
      });

      metrics.totalResponses += session.totalResponses;
    });

    return metrics;
  }
  
  /**
   * üîí CORRE√á√ÉO DE CONCORR√äNCIA: Limpeza seletiva por telefone
   * Remove apenas entrevistas antigas do mesmo telefone, preservando outras pessoas
   */
  private async cleanupStaleInterviewsForPhone(phone: string): Promise<void> {
    try {
      const existingInterview = this.activeInterviews.get(phone);
      
      if (existingInterview) {
        // Verificar se entrevista √© muito antiga (mais de 1 hora)
        const oneHourAgo = Date.now() - (60 * 60 * 1000);
        const interviewStartTime = new Date(existingInterview.startTime).getTime();
        
        if (interviewStartTime < oneHourAgo) {
          console.log(`üßπ Limpando entrevista antiga para ${phone} (${Math.round((Date.now() - interviewStartTime) / (60 * 1000))} min atr√°s)`);
          
          // Tentar salvar progresso antes de limpar
          if (existingInterview.interviewDbId) {
            try {
              await storage.updateInterview(parseInt(existingInterview.interviewDbId), { 
                status: 'timeout' 
              });
            } catch (error) {
              console.error(`‚ùå Erro ao salvar entrevista antiga:`, error);
            }
          }
          
          this.activeInterviews.delete(phone);
          console.log(`‚úÖ Entrevista antiga removida para ${phone}`);
        } else {
          console.log(`‚ö†Ô∏è Entrevista recente detectada para ${phone}, mantendo ativa`);
        }
      }
    } catch (error) {
      console.error(`‚ùå Erro na limpeza seletiva para ${phone}:`, error);
    }
  }
  
  /**
   * üîç M√âTODO DE DETEC√á√ÉO ROBUSTA DE CLIENTE
   * Detecta o clientId correto baseado no telefone do candidato
   * PRIORIZA O ISOLAMENTO POR CLIENTE - busca apenas no escopo do cliente logado
   */
  private async detectClientIdRobust(phone: string, clientId?: string): Promise<string | null> {
    console.log(`üîç [DETECT] Detectando clientId para telefone ${phone}, clientId fornecido: ${clientId}`);
    
    // Se clientId fornecido for v√°lido, usar esse E buscar apenas candidatos desse cliente
    if (clientId && clientId !== 'undefined' && clientId !== 'null') {
      try {
        console.log(`üîç [DETECT] Buscando candidatos do cliente ${clientId}`);
        // üîí ISOLAMENTO: Buscar candidatos APENAS do cliente logado
        const clientCandidates = await storage.getCandidatesByClientId(parseInt(clientId));
        console.log(`üîç [DETECT] Encontrados ${clientCandidates.length} candidatos no cliente ${clientId}`);
        
        // Limpar telefone para compara√ß√£o (apenas n√∫meros)
        const cleanPhone = phone.replace(/\D/g, '');
        console.log(`üîç [DETECT] Telefone limpo para compara√ß√£o: ${cleanPhone}`);
        
        // Buscar candidato correspondente no escopo do cliente
        const matchingCandidate = clientCandidates.find(candidate => {
          const candidatePhone = candidate.whatsapp?.replace(/\D/g, '') || '';
          console.log(`üîç [DETECT] Comparando ${cleanPhone} com ${candidatePhone} (${candidate.name})`);
          return candidatePhone === cleanPhone;
        });
        
        // Se encontrou candidato no cliente logado, confirmar o clientId
        if (matchingCandidate) {
          console.log(`‚úÖ [DETECT] Candidato encontrado: ${matchingCandidate.name} no cliente ${clientId}`);
          return clientId;
        } else {
          // Candidato n√£o pertence a este cliente - viola√ß√£o de isolamento
          console.log(`‚ö†Ô∏è [DETECT] Telefone ${phone} n√£o encontrado no cliente ${clientId} - isolamento respeitado`);
          return null;
        }
        
      } catch (error) {
        console.error(`‚ùå [DETECT] Erro ao buscar candidatos do cliente ${clientId}:`, error);
        return null;
      }
    }
    
    console.log(`‚ö†Ô∏è [DETECT] ClientId n√£o fornecido ou inv√°lido: ${clientId}`);
    return null;
  }

  /**
   * ‚úÖ M√âTODO DE VALIDA√á√ÉO COMPLETA COM ISOLAMENTO POR USU√ÅRIO
   * Valida se o cliente est√° apto para receber cad√™ncia usando conex√µes isoladas
   */
  private async validateClientForCadence(clientId: string, phone: string): Promise<boolean> {
    try {
      // VALIDA√á√ÉO 1: Verificar conex√µes WhatsApp ativas ISOLADAS por usu√°rio
      // üîí ISOLAMENTO: Usar userIsolatedRoundRobin para garantir que apenas 
      //    conex√µes do usu√°rio logado sejam verificadas
      
      // Mapear clientId para userId (neste sistema, clientId √© o userId)
      const userId = clientId;
      
      // Inicializar slots do usu√°rio se necess√°rio
      await userIsolatedRoundRobin.initializeUserSlots(userId, clientId);
      
      // Verificar se usu√°rio tem slots ativos (conex√µes WhatsApp funcionais)
      const activeSlots = userIsolatedRoundRobin.getUserActiveSlots(userId);
      console.log(`üîç [VALIDATE] Slots ativos encontrados para usu√°rio ${userId}: ${activeSlots.length}`);
      
      if (activeSlots.length === 0) {
        console.log(`‚ùå [VALIDATE] Cliente ${clientId} n√£o possui conex√µes WhatsApp ativas isoladas`);
        return false;
      }
      
      // Obter estat√≠sticas isoladas do usu√°rio
      const userStats = userIsolatedRoundRobin.getUserStats(userId);
      console.log(`üîç [VALIDATE] Estat√≠sticas do usu√°rio ${userId}:`, userStats);
      
      if (userStats.activeSlots === 0) {
        console.log(`‚ùå [VALIDATE] Cliente ${clientId} - slots ativos: ${userStats.activeSlots}`);
        return false;
      }
      
      console.log(`‚úÖ [VALIDATE] Cliente ${clientId} - ${userStats.activeSlots} conex√µes ativas isoladas`);
      
      // VALIDA√á√ÉO 2: Verificar se candidato existe na base do cliente (isolamento por cliente)
      const candidatesByClient = await storage.getCandidatesByClientId(parseInt(clientId));
      
      const cleanPhone = phone.replace(/\D/g, '');
      const candidateExists = candidatesByClient.some(candidate => {
        const candidatePhone = candidate.whatsapp?.replace(/\D/g, '') || '';
        return candidatePhone === cleanPhone;
      });
      
      if (!candidateExists) {
        console.log(`‚ùå Candidato ${phone} n√£o encontrado na base do cliente ${clientId}`);
        return false;
      }
      
      // VALIDA√á√ÉO 3: Verificar se telefone confere exatamente
      const matchingCandidate = candidatesByClient.find(candidate => {
        const candidatePhone = candidate.whatsapp?.replace(/\D/g, '') || '';
        return candidatePhone === cleanPhone;
      });
      
      if (!matchingCandidate) {
        console.log(`‚ùå Telefone ${phone} n√£o confere exatamente no cliente ${clientId}`);
        return false;
      }
      
      // VALIDA√á√ÉO 4: Verificar isolamento entre usu√°rios
      const isIsolated = userIsolatedRoundRobin.validateUserIsolation();
      
      if (!isIsolated) {
        console.log(`‚ö†Ô∏è Viola√ß√£o de isolamento detectada - cad√™ncia suspensa por seguran√ßa`);
        return false;
      }
      
      console.log(`‚úÖ Todas as valida√ß√µes passaram para cliente ${clientId}, telefone ${phone}`);
      return true;
      
    } catch (error) {
      console.error(`‚ùå Erro na valida√ß√£o de cad√™ncia para cliente ${clientId}:`, error);
      return false;
    }
  }

  /**
   * üî• CR√çTICO: Ativar cad√™ncia imediata com isolamento por usu√°rio
   * Esta fun√ß√£o √© chamada quando um contato responde "1"
   */
  private async activateUserImmediateCadence(phone: string, clientId?: string): Promise<void> {
    console.log(`üöÄ [CADENCIA] Iniciando ativa√ß√£o de cad√™ncia imediata para ${phone}, clientId: ${clientId}`);
    
    // üîç ETAPA 1: DETEC√á√ÉO ROBUSTA DE CLIENTE
    const detectedClientId = await this.detectClientIdRobust(phone, clientId);
    
    if (!detectedClientId) {
      console.log(`‚ùå [CADENCIA] ClientId n√£o detectado para ${phone} - cad√™ncia abortada`);
      return;
    }
    console.log(`‚úÖ [CADENCIA] ClientId detectado: ${detectedClientId} para ${phone}`);
    
    // ‚úÖ ETAPA 2: VALIDA√á√ÉO COMPLETA
    const isValid = await this.validateClientForCadence(detectedClientId, phone);
    
    if (!isValid) {
      console.log(`‚ùå [CADENCIA] Valida√ß√£o falhou para cliente ${detectedClientId}, telefone ${phone} - cad√™ncia abortada`);
      return;
    }
    console.log(`‚úÖ [CADENCIA] Valida√ß√£o passou para cliente ${detectedClientId}, telefone ${phone}`);

    try {
      // Mapear clientId para userId (neste sistema, clientId √© o userId)
      const userId = detectedClientId;
      console.log(`üîß [CADENCIA] Mapeando clientId para userId: ${userId}`);
      
      // üî• ETAPA 3: Inicializar slots se necess√°rio
      console.log(`üîß [CADENCIA] Inicializando slots para usu√°rio ${userId}`);
      await userIsolatedRoundRobin.initializeUserSlots(userId, detectedClientId);
      
      // üî• ETAPA 4: Configurar cad√™ncia imediata para o usu√°rio
      console.log(`üîß [CADENCIA] Configurando cad√™ncia imediata para usu√°rio ${userId}`);
      userIsolatedRoundRobin.setUserCadenceConfig(userId, {
        userId,
        baseDelay: 500, // Delay reduzido para resposta "1"
        batchSize: 1, // Envios individuais
        maxRetries: 3,
        adaptiveMode: false, // Modo fixo para resposta imediata
        immediateMode: true // Modo imediato ativado
      });
      
      // üî• ETAPA 5: Distribuir apenas o candidato que respondeu "1"
      console.log(`üîß [CADENCIA] Distribuindo candidato ${phone} para usu√°rio ${userId}`);
      await userIsolatedRoundRobin.distributeUserCandidates(userId, detectedClientId, [phone], 'immediate');
      
      // üî• ETAPA 6: Ativar cad√™ncia imediata espec√≠fica do usu√°rio
      console.log(`üîß [CADENCIA] Ativando cad√™ncia imediata para usu√°rio ${userId}, candidato ${phone}`);
      await userIsolatedRoundRobin.activateImmediateCadence(userId, detectedClientId, phone);
      
      // üî• ETAPA 7: Validar isolamento entre usu√°rios
      const isIsolated = userIsolatedRoundRobin.validateUserIsolation();
      console.log(`üîß [CADENCIA] Isolamento validado: ${isIsolated}`);
      
      // üî• ETAPA 8: Aguardar 1 segundo e processar cad√™ncia garantindo execu√ß√£o
      console.log(`üîß [CADENCIA] Agendando processamento de cad√™ncia em 1 segundo para usu√°rio ${userId}`);
      setTimeout(async () => {
        try {
          console.log(`üöÄ [CADENCIA] Executando processamento de cad√™ncia para usu√°rio ${userId}`);
          await userIsolatedRoundRobin.processUserCadence(userId, detectedClientId);
          console.log(`‚úÖ [CADENCIA] Processamento de cad√™ncia conclu√≠do para usu√°rio ${userId}`);
        } catch (error) {
          console.error(`‚ùå [CADENCIA] Erro no processamento de cad√™ncia para usu√°rio ${userId}:`, error);
        }
      }, 1000);
      
    } catch (error) {
      console.error(`‚ùå [CADENCIA] Erro na ativa√ß√£o de cad√™ncia imediata para ${phone}:`, error);
    }
  }



  // üîß M√âTODO PARA CONVERTER CAMINHO ABSOLUTO EM URL HTTP
  private convertToHttpPath(absolutePath: string): string {
    try {
      // Extrair apenas o nome do arquivo do caminho absoluto
      const path = require('path');
      const filename = path.basename(absolutePath);
      
      // Retornar URL HTTP que ser√° servida pela rota /api/audio/:filename
      const httpUrl = `/api/audio/${filename}`;
      
      console.log(`üîó [HTTP-PATH] Convertendo: ${absolutePath} ‚Üí ${httpUrl}`);
      return httpUrl;
    } catch (error) {
      console.error(`‚ùå [HTTP-PATH] Erro na convers√£o:`, error);
      return absolutePath; // Fallback para caminho original
    }
  }

  private async downloadAudioDirect(message: any, phone: string, clientId: string, selectionId: string, questionNumber: number): Promise<string | null> {
    try {
      console.log(`üîç [DEBUG-DOWNLOAD] Iniciando download para:`, {
        phone,
        clientId,
        selectionId,
        questionNumber,
        hasMessage: !!message,
        hasAudioMessage: !!message?.message?.audioMessage
      });
      
      const { UPLOADS_DIR } = await import('../src/config/paths');
      const path = await import('path');
      
      const cleanPhone = phone.replace(/\D/g, '');
      // Nova nomenclatura: audio_[whatsapp]_[selectionId]_R[numero].ogg
      const audioFileName = `audio_${cleanPhone}_${selectionId}_R${questionNumber}.ogg`;
      const audioPath = path.join(UPLOADS_DIR, audioFileName);
      
      console.log(`üìÅ [DEBUG-DOWNLOAD] Path do arquivo: ${audioPath}`);
      
      // üîß CORRE√á√ÉO: Verificar se arquivo j√° existe e √© v√°lido (n√£o placeholder)
      const fs = await import('fs');
      try {
        const stats = await fs.promises.stat(audioPath);
        if (isValidAudio(stats.size)) {
          console.log(`‚úÖ [√ÅUDIO-CORRIGIDO] Arquivo v√°lido encontrado: ${audioPath} (${stats.size} bytes)`);
          return audioPath;
        } else {
          // Remove arquivo inv√°lido/placeholder para for√ßar novo download
          console.log(`üóëÔ∏è [√ÅUDIO-CORRIGIDO] Removendo placeholder inv√°lido: ${audioPath} (${stats.size} bytes)`);
          await fs.promises.unlink(audioPath).catch(() => {});
        }
      } catch {
        // Arquivo n√£o existe, continuar com download
      }
      
      let audioBuffer: Buffer | null = null;
      
      // M√âTODO 1: Tentar usar buffer j√° processado (se dispon√≠vel)
      if (message._audioBuffer && isValidAudioBuffer(message._audioBuffer)) {
        audioBuffer = message._audioBuffer;
        console.log(`üì• [DEBUG-DOWNLOAD] Usando buffer pr√©-processado v√°lido (${audioBuffer.length} bytes)`);
      } else {
        console.log(`‚ö†Ô∏è [DEBUG-DOWNLOAD] Buffer pr√©-processado n√£o dispon√≠vel:`, {
          hasAudioBuffer: !!message._audioBuffer,
          isValid: message._audioBuffer ? isValidAudioBuffer(message._audioBuffer) : false
        });
      }
      
      // M√âTODO 2: Download direto via userIsolatedRoundRobin (m√©todo mais confi√°vel)
      if (!audioBuffer && message.message?.audioMessage) {
        try {
          const userId = clientId;
          console.log(`üîç [DEBUG-DOWNLOAD] Tentando download via userIsolatedRoundRobin para usu√°rio ${userId}`);
          
          const connectionStatus = await userIsolatedRoundRobin.getUserConnectionStatus(userId, clientId);
          console.log(`üì± [DEBUG-DOWNLOAD] Status da conex√£o:`, {
            isConnected: connectionStatus.isConnected,
            slotsCount: connectionStatus.slots.length,
            userId,
            clientId
          });
          
          if (connectionStatus.isConnected && connectionStatus.slots.length > 0) {
            try {
              console.log(`üì• [DEBUG-DOWNLOAD] Baixando √°udio via userIsolatedRoundRobin...`);
              
              audioBuffer = await userIsolatedRoundRobin.downloadUserAudio(userId, clientId, message);
              
              if (audioBuffer && isValidAudioBuffer(audioBuffer)) {
                console.log(`‚úÖ [DEBUG-DOWNLOAD] √Åudio baixado com sucesso via isolamento (${audioBuffer.length} bytes)`);
              } else {
                console.log(`‚ùå [DEBUG-DOWNLOAD] Buffer inv√°lido do isolamento: ${audioBuffer?.length || 0} bytes`);
                audioBuffer = null;
              }
            } catch (isolatedDownloadError: any) {
              console.log(`‚ùå [DEBUG-DOWNLOAD] Erro no download isolado:`, isolatedDownloadError.message);
              audioBuffer = null;
            }
          } else {
            console.log(`‚ö†Ô∏è [DEBUG-DOWNLOAD] Nenhuma conex√£o isolada ativa para usu√°rio ${userId}`);
          }
        } catch (baileyError: any) {
          console.log(`‚ùå [DEBUG-DOWNLOAD] Erro no Baileys:`, baileyError.message);
        }
      }
      
      // M√âTODO 3: Fallback com downloadContentFromMessage (API mais nova do Baileys)
      if (!audioBuffer && message.message?.audioMessage) {
        try {
          console.log(`üì• [√ÅUDIO-CORRIGIDO] Tentando download com API mais nova do Baileys`);
          
          const { downloadContentFromMessage } = await import('@whiskeysockets/baileys');
          
          const stream = await downloadContentFromMessage(
            message.message.audioMessage,
            'audio'
          );
          
          const chunks: Buffer[] = [];
          for await (const chunk of stream) {
            chunks.push(chunk);
          }
          audioBuffer = Buffer.concat(chunks);
          
          if (audioBuffer && isValidAudioBuffer(audioBuffer)) {
            console.log(`‚úÖ [√ÅUDIO-CORRIGIDO] √Åudio baixado com API nova (${audioBuffer.length} bytes)`);
          } else {
            console.log(`‚ùå [√ÅUDIO-CORRIGIDO] Buffer inv√°lido da API nova: ${audioBuffer?.length || 0} bytes`);
            audioBuffer = null;
          }
        } catch (newApiError: any) {
          console.log(`‚ùå [√ÅUDIO-CORRIGIDO] Erro na API nova:`, newApiError);
          audioBuffer = null;
        }
      }
      
      // M√âTODO 4: Fallback com downloadMediaMessage
      if (!audioBuffer) {
        try {
          console.log(`üì• [√ÅUDIO-CORRIGIDO] Fallback com downloadMediaMessage`);
          
          const { downloadMediaMessage } = await import('@whiskeysockets/baileys');
          
          audioBuffer = await downloadMediaMessage(
            message,
            'buffer',
            {}
          );
          
          if (audioBuffer && isValidAudioBuffer(audioBuffer)) {
            console.log(`‚úÖ [√ÅUDIO-CORRIGIDO] √Åudio baixado via fallback (${audioBuffer.length} bytes)`);
          } else {
            console.log(`‚ùå [√ÅUDIO-CORRIGIDO] Buffer inv√°lido do fallback: ${audioBuffer?.length || 0} bytes`);
            audioBuffer = null;
          }
        } catch (fallbackError: any) {
          console.log(`‚ùå [√ÅUDIO-CORRIGIDO] Erro no fallback:`, fallbackError);
          audioBuffer = null;
        }
      }
      
      // üîß CORRE√á√ÉO CR√çTICA: N√ÉO CRIAR PLACEHOLDER - Lan√ßar erro se buffer inv√°lido
      if (!audioBuffer || !isValidAudioBuffer(audioBuffer)) {
        const errorMsg = `Falha no download do √°udio ‚Äì buffer inv√°lido (${audioBuffer?.length || 0} bytes, m√≠nimo: ${MIN_AUDIO_SIZE})`;
        console.error(`‚ùå [√ÅUDIO-CORRIGIDO] ${errorMsg}`);
        throw new Error(errorMsg);
      }
      
      // Salvar o √°udio v√°lido
      await fs.promises.writeFile(audioPath, audioBuffer);
      
      // Verificar se arquivo foi realmente salvo
      const verifyStats = await fs.promises.stat(audioPath);
      console.log(`‚úÖ [√ÅUDIO-CORRIGIDO] Arquivo salvo: ${audioPath} (${verifyStats.size} bytes)`);
      
      return audioPath;
      
    } catch (error: any) {
      console.error(`‚ùå [√ÅUDIO-CORRIGIDO] Erro cr√≠tico no download:`, error.message);
      throw error; // üîß CORRE√á√ÉO: Propagar erro em vez de retornar null
    }
  }

  // üöÄ NOVO SISTEMA DE CONTROLE DE CONCORR√äNCIA COM FILAS
  async handleMessage(from: string, text: string, audioMessage?: any, clientId?: string): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    
    // üìù ETAPA 3: ADICIONAR RESPOSTA √Ä FILA COM CONTROLE DE CONCORR√äNCIA
    const responseId = `${phone}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const queuedResponse: QueuedResponse = {
      id: responseId,
      phone,
      text,
      audioMessage,
      timestamp: Date.now(),
      processed: false
    };
    
    // Detectar clientId se n√£o fornecido
    if (!clientId) {
      clientId = await this.detectClientIdRobust(phone);
      if (!clientId) {
        console.log(`‚ö†Ô∏è [QUEUE] ClientId n√£o detectado para ${phone} - mensagem ignorada`);
        return;
      }
    }
    
    console.log(`üîç [HANDLE-MESSAGE] Mensagem recebida: phone=${phone}, text="${text}", clientId=${clientId}`);
    
    // Adicionar √† fila
    this.queueManager.enqueue(phone, queuedResponse);
    
    // üîÑ PROCESSAR FILA COM LOCK AUTOM√ÅTICO
    await this.processQueueForPhone(phone, clientId);
  }
  
  // üîÑ NOVO M√âTODO: PROCESSAR FILA DE RESPOSTAS COM MUTEX
  private async processQueueForPhone(phone: string, clientId: string): Promise<void> {
    const queueStatus = this.queueManager.getQueueStatus(phone);
    
    // Se j√° est√° processando, n√£o fazer nada (evita race condition)
    if (queueStatus.isProcessing || queueStatus.isLocked) {
      console.log(`üîí [QUEUE] Telefone ${phone} j√° em processamento (fila: ${queueStatus.size})`);
      return;
    }
    
    // Processar respostas uma por uma at√© esvaziar a fila
    while (true) {
      const response = await this.queueManager.dequeue(phone);
      
      if (!response) {
        break; // Fila vazia ou lock em outro processo
      }
      
      try {
        const startTime = Date.now();
        
        // üìä ETAPA 5: MONITORAMENTO DE PERFORMANCE
        console.log(`‚ö° [QUEUE] Processando resposta ${response.id} (fila: ${this.queueManager.getQueueStatus(phone).size})`);
        
        // PROCESSAR A RESPOSTA INDIVIDUALMENTE
        await this.handleSingleResponse(response, clientId);
        
        const processingTime = Date.now() - startTime;
        console.log(`‚úÖ [QUEUE] Resposta ${response.id} processada em ${processingTime}ms`);
        
        // Atualizar m√©tricas de performance na sess√£o
        const session = this.activeSessions.get(phone);
        if (session) {
          session.totalResponses++;
          session.processingTimeMs.push(processingTime);
          session.lastActivity = Date.now();
          
          // Manter apenas √∫ltimas 10 m√©tricas
          if (session.processingTimeMs.length > 10) {
            session.processingTimeMs = session.processingTimeMs.slice(-10);
          }
        }
        
      } catch (error) {
        console.error(`‚ùå [QUEUE] Erro ao processar resposta ${response.id}:`, error);
      } finally {
        // üîì SEMPRE liberar lock
        this.queueManager.unlock(phone);
      }
    }
  }
  
  // üéØ M√âTODO INDIVIDUAL PARA PROCESSAR UMA RESPOSTA (SEM CONCORR√äNCIA)
  private async handleSingleResponse(response: QueuedResponse, clientId: string): Promise<void> {
    const { phone, text, audioMessage } = response;
    const activeInterview = this.activeInterviews.get(phone);
    
    console.log(`üîç [DEBUG-RESPONSE] Processando resposta: phone=${phone}, text="${text}", activeInterview=${!!activeInterview}, clientId=${clientId}`);
    
    if (text === '1' && !activeInterview) {
      console.log(`üöÄ [DEBUG-CADENCIA] Resposta "1" detectada para ${phone} - iniciando cad√™ncia E entrevista`);
      // PRIMEIRO: Remover da cad√™ncia e ativar cad√™ncia imediata
      userIsolatedRoundRobin.removeCandidateFromActiveCadence(phone);
      await this.activateUserImmediateCadence(phone, clientId);
      
      // SEGUNDO: Limpar entrevistas antigas e iniciar nova
      await this.cleanupStaleInterviewsForPhone(phone);
      await this.startInterview(phone, clientId);
      
    } else if (text === '2') {
      userIsolatedRoundRobin.removeCandidateFromActiveCadence(phone);
      await this.sendMessage(phone + '@s.whatsapp.net', "Entendido. Obrigado!", clientId);
      
    } else if (text.toLowerCase() === 'parar' || text.toLowerCase() === 'sair') {
      await this.stopInterview(phone, clientId);
      
    } else if (activeInterview && text !== '1') {
      // Verificar estado v√°lido
      if (activeInterview.currentQuestion >= activeInterview.questions.length) {
        this.activeInterviews.delete(phone);
        return;
      }
      
      // üîÑ ETAPA 4: PROCESSAR RESPOSTA E AVAN√áAR ENTREVISTA
      try {
        console.log(`üîç [INTERVIEW] Processando resposta para pergunta ${activeInterview.currentQuestion + 1}/${activeInterview.questions.length}`);
        await this.processInterviewResponse(phone, activeInterview, text, audioMessage);
        console.log(`‚úÖ [INTERVIEW] Resposta processada com sucesso para ${phone}`);
      } catch (error) {
        console.error(`‚ùå [INTERVIEW] Erro ao processar resposta:`, error);
        // Em caso de erro, manter pergunta atual para retry
      }
      
    } else {
      // Mensagem padr√£o apenas se n√£o estiver em cad√™ncia
      const isInActiveCadence = userIsolatedRoundRobin.isPhoneInActiveCadence(phone);
      
      if (!isInActiveCadence) {
        await this.sendMessage(phone + '@s.whatsapp.net', "Digite:\n1 - Iniciar entrevista\n2 - N√£o participar", clientId);
      }
    }
  }

  private async startInterview(phone: string, clientId?: string): Promise<void> {
    // Buscar candidato
    const candidate = await this.findCandidate(phone, clientId);
    if (!candidate) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Candidato n√£o encontrado.", clientId);
      return;
    }

    // CORRE√á√ÉO CR√çTICA: Limpar entrevista ativa antiga antes de iniciar nova
    if (this.activeInterviews.has(phone)) {
      this.activeInterviews.delete(phone);
    }

    // CORRE√á√ÉO: Buscar sempre a sele√ß√£o mais recente independente do status (para suportar duplica√ß√£o)
    try {
      const allSelections = await storage.getAllSelections();
      
      // Filtrar por cliente e ordenar por ID (mais recente primeiro - IDs s√£o timestamps)
      const clientSelections = allSelections
        .filter(s => clientId ? s.clientId.toString() === clientId : true)
        .sort((a, b) => parseInt(b.id.toString()) - parseInt(a.id.toString()));
      
      // Pegar a mais recente independente do status
      const selection = clientSelections[0];

      if (!selection) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Nenhuma vaga dispon√≠vel no momento.", clientId);
        return;
      }

      // Buscar job da sele√ß√£o
      const job = await storage.getJobById(selection.jobId);
      if (!job || !job.perguntas || job.perguntas.length === 0) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Vaga n√£o possui perguntas cadastradas.", clientId);
        return;
      }
      
      // üîß CORRE√á√ÉO CR√çTICA: Usar sempre o ID real do candidato para evitar problemas no JOIN
      const uniqueInterviewId = `${selection.id}_${phone.replace(/\D/g, '')}_${Date.now()}`;
      const realCandidateId = candidate.id; // ID real da tabela candidates
      
      // Criar entrevista no banco de dados com ID real do candidato
      const interviewDb = await storage.createInterview({
        id: uniqueInterviewId,
        selectionId: selection.id,
        candidateId: realCandidateId.toString(), // Usar ID real como string
        token: `whatsapp_${Date.now()}`,
        status: 'in_progress'
      });

      // üèóÔ∏è CRIAR NOVA SESS√ÉO CENTRALIZADA COM CONTROLE DE CONCORR√äNCIA
      const session: InterviewSession = {
        // Estado da entrevista (legado)
        candidateId: realCandidateId,
        candidateName: candidate.name,
        phone: phone,
        jobId: parseInt(job.id.toString()),
        jobName: job.nomeVaga,
        clientId: selection.clientId.toString(),
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString(),
        selectionId: selection.id.toString(),
        interviewDbId: uniqueInterviewId,
        
        // üîí Controle de concorr√™ncia
        responseQueue: [],
        isProcessing: false,
        lock: false,
        lastActivity: Date.now(),
        
        // üìä Monitoramento
        totalResponses: 0,
        queuePeakSize: 0,
        processingTimeMs: []
      };

      // üî• CORRE√á√ÉO CR√çTICA: SALVAR SESS√ÉO EM AMBOS OS SISTEMAS
      this.activeSessions.set(phone, session);
      
      // üîß BRIDGE CORRE√á√ÉO: Criar entrevista compat√≠vel para activeInterviews
      const activeInterview: ActiveInterview = {
        candidateId: realCandidateId,
        candidateName: candidate.name,
        phone: phone,
        jobId: parseInt(job.id.toString()),
        jobName: job.nomeVaga,
        clientId: selection.clientId.toString(),
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString(),
        selectionId: selection.id.toString(),
        interviewDbId: uniqueInterviewId
      };
      
      this.activeInterviews.set(phone, activeInterview);
      console.log(`üèóÔ∏è [BRIDGE-SYNC] Entrevista sincronizada em ambos sistemas para ${phone} (clientId: ${selection.clientId})`);

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `üéØ Entrevista iniciada para: ${job.nomeVaga}\nüëã Ol√° ${candidate.name}!\nüìù ${job.perguntas.length} perguntas\n\n‚è≥ Preparando primeira pergunta...`, 
        clientId
      );

      // Enviar primeira pergunta ap√≥s pequeno delay
      setTimeout(async () => {
        const currentInterview = this.activeInterviews.get(phone);
        if (currentInterview) {
          console.log(`üì§ [START-QUESTION] Enviando primeira pergunta para ${phone}`);
          await this.sendNextQuestion(phone, currentInterview);
        }
      }, 2000);
      
    } catch (error) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Erro ao carregar entrevista. Tente novamente.", clientId);
    }
  }

  private async sendNextQuestion(phone: string, interview: ActiveInterview): Promise<void> {
    // üî• CORRE√á√ÉO CR√çTICA: Verificar se j√° respondeu todas as perguntas
    if (interview.currentQuestion >= interview.questions.length) {
      await this.finishInterview(phone, interview);
      return;
    }
    
    const question = interview.questions[interview.currentQuestion];
    
    if (!question) {
      await this.finishInterview(phone, interview);
      return;
    }

    const questionNum = interview.currentQuestion + 1;
    const total = interview.questions.length;
    
    const message = `üìù Pergunta ${questionNum}/${total}:\n\n${question.pergunta}\n\nüé§ Responda somente por √°udio`;

    await this.sendMessage(`${phone}@s.whatsapp.net`, message, interview.clientId);

    // Tentar enviar √°udio TTS
    try {
      await this.sendQuestionAudio(phone, question.pergunta, interview.clientId);
    } catch (error) {
    }
  }

  private async sendQuestionAudio(phone: string, questionText: string, clientId: string): Promise<void> {
    try {
      // Buscar configura√ß√£o OpenAI
      const config = await storage.getMasterSettings();
      
      if (!config) {
        return;
      }
      
      if (!config.openaiApiKey) {
        // Verificar se existe na vari√°vel de ambiente
        const envKey = process.env.OPENAI_API_KEY;
        if (envKey) {
          config.openaiApiKey = envKey;
        } else {
          return;
        }
      }

      // Buscar configura√ß√£o de voz do cliente
      const clientConfig = await storage.getApiConfig('client', clientId);
      const voice = clientConfig?.openaiVoice || 'nova';
      
      console.log(`üîä [TTS-CONFIG] Cliente ${clientId}: configura√ß√£o encontrada =`, clientConfig);
      console.log(`üîä [TTS-CONFIG] Voz selecionada para entrevista: "${voice}"`);

      const ttsRequest = {
        model: "tts-1",
        input: questionText,
        voice: voice,
        response_format: "opus",
        speed: 1.0
      };

      const response = await fetch("https://api.openai.com/v1/audio/speech", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${config.openaiApiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify(ttsRequest)
      });

      if (response.ok) {
        const audioBuffer = await response.arrayBuffer();
        
        // üîí ISOLAMENTO: Tentar enviar √°udio via slots isolados do usu√°rio
        try {
          const fs = await import('fs');
          const path = await import('path');
          
          // Salvar √°udio tempor√°rio para envio
          const tempDir = path.join(process.cwd(), 'temp');
          if (!fs.existsSync(tempDir)) {
            fs.mkdirSync(tempDir, { recursive: true });
          }
          
          const tempFileName = `tts_${phone}_${Date.now()}.ogg`;
          const tempFilePath = path.join(tempDir, tempFileName);
          
          // Salvar buffer como arquivo
          fs.writeFileSync(tempFilePath, Buffer.from(audioBuffer));
          
          // ‚úÖ CORRE√á√ÉO ARQUITETURAL: Usar userIsolatedRoundRobin como camada √∫nica
          const userId = clientId;
          
          try {
            const result = await userIsolatedRoundRobin.sendUserAudio(
              userId,
              clientId,
              phone,
              Buffer.from(audioBuffer)
            );
            
            if (result?.success) {
              console.log(`üîä [CORRIGIDO] √Åudio TTS enviado via slot isolado ${result.usedSlot} do usu√°rio ${userId}`);
            } else {
              console.log(`‚ö†Ô∏è [CORRIGIDO] Falha no envio de √°udio isolado para usu√°rio ${userId}: ${result.error}`);
            }
                    } catch (isolatedAudioError) {
            console.log(`‚ùå [CORRIGIDO] Erro no envio de √°udio isolado para usu√°rio ${userId}:`, isolatedAudioError);
          }
          
          // Limpar arquivo tempor√°rio
          setTimeout(() => {
            try {
              if (fs.existsSync(tempFilePath)) {
                fs.unlinkSync(tempFilePath);
              }
            } catch (cleanupError) {
            }
          }, 10000); // Remover ap√≥s 10 segundos
          
        } catch (audioError: any) {
        }
      } else {
        const errorText = await response.text();
      }
    } catch (error: any) {
    }
  }

  private async processInterviewResponse(phone: string, interview: ActiveInterview, text: string, audioMessage?: any): Promise<void> {

    let responseText = text;
    let audioFile: string | undefined;
    let finalTranscription = text; // üîß CORRE√á√ÉO: Usar texto inicial

    // üîß CORRE√á√ÉO: CHAMADA √öNICA de transcri√ß√£o
    if (audioMessage) {
      try {
        console.log(`üé§ [√ÅUDIO-CORRIGIDO] Processando √°udio para ${phone}`);
        
        // Baixar √°udio com valida√ß√£o rigorosa
        const audioPath = await this.downloadAudioDirect(
          audioMessage, 
          phone, 
          interview.clientId, 
          interview.selectionId, 
          interview.currentQuestion + 1
        );
        
        if (audioPath) {
          audioFile = audioPath;
          
          // üîß CORRE√á√ÉO: Transcrever apenas UMA VEZ
          try {
            console.log(`üé§ [TRANSCRIPTION-CORRIGIDO] Iniciando transcri√ß√£o √∫nica para ${phone}`);
            const transcription = await this.transcribeAudio(audioPath, phone);
            
            // üîß CORRE√á√ÉO: Usar transcri√ß√£o v√°lida ou texto padr√£o
            finalTranscription = transcription || '√Åudio recebido';
            responseText = finalTranscription;
            
            console.log(`‚úÖ [TRANSCRIPTION-CORRIGIDO] Transcri√ß√£o completa: "${finalTranscription.substring(0, 100)}..."`);
          } catch (transcribeError: any) {
            console.error(`‚ùå [TRANSCRIPTION-CORRIGIDO] Erro na transcri√ß√£o:`, transcribeError.message);
            console.error(`üîç [DEBUG-TRANSCRIPTION] Details:`, {
              audioPath,
              errorType: transcribeError.constructor.name,
              hasOpenAI: !!process.env.OPENAI_API_KEY
            });
            
            // üîß CORRE√á√ÉO: Usar texto padr√£o informativo
            finalTranscription = '√Åudio recebido via WhatsApp';
            responseText = finalTranscription;
          }
        } else {
          console.error(`‚ùå [√ÅUDIO-CORRIGIDO] Falha no download do √°udio para ${phone}`);
          console.error(`üîç [DEBUG-AUDIO] Message details:`, {
            hasAudioMessage: !!audioMessage?.message?.audioMessage,
            messageType: typeof audioMessage,
            clientId: interview.clientId,
            selectionId: interview.selectionId,
            questionNumber: interview.currentQuestion + 1
          });
          
          // üîß CORRE√á√ÉO CR√çTICA: Usar texto padr√£o em vez de "erro"
          finalTranscription = '√Åudio recebido via WhatsApp - aguardando processamento';
          responseText = finalTranscription;
        }
      } catch (audioError: any) {
        console.error(`‚ùå [√ÅUDIO-CORRIGIDO] Erro cr√≠tico no processamento:`, audioError.message);
        console.error(`üîç [DEBUG-AUDIO] Stack trace:`, audioError.stack);
        
        // üîß CORRE√á√ÉO CR√çTICA: Usar texto padr√£o em vez de "erro"
        finalTranscription = '√Åudio recebido via WhatsApp - processamento em andamento';
        responseText = finalTranscription;
      }
    }

    // Salvar resposta na entrevista ativa
    const currentQuestion = interview.questions[interview.currentQuestion];
    const response = {
      questionId: interview.currentQuestion + 1, // üîß CORRE√á√ÉO: +1 para match com frontend
      questionText: currentQuestion.pergunta,
      transcription: finalTranscription, // üîß CORRE√á√ÉO: usar nome que o frontend espera
      audioUrl: audioFile ? this.convertToHttpPath(audioFile) : '', // üîß CORRE√á√ÉO: converter para URL HTTP
      timestamp: new Date().toISOString()
    };

    interview.responses.push(response);

    // Salvar resposta no banco de dados
    try {
      if (interview.interviewDbId) {
        const cleanPhone = interview.phone.replace(/\D/g, '');
        const transcriptionId = `candidato_${interview.selectionId}_${interview.currentQuestion + 1}`;
        const responseId = `${interview.selectionId}_${interview.candidateId}_R${interview.currentQuestion + 1}_${Date.now()}`;
        
        // Verificar se j√° existe score calculado
        let pontuacao = 50; // Valor padr√£o
        
        const existingResponses = await storage.getResponsesBySelectionAndCandidate(
          interview.selectionId, 
          interview.candidateId, 
          parseInt(interview.clientId)
        );
        const existingResponse = existingResponses.find(r => 
          r.questionId === (interview.currentQuestion + 1) && r.score !== null && r.score !== undefined
        );
        
        if (existingResponse && existingResponse.score !== null && existingResponse.score !== undefined && existingResponse.score > 0) {
          pontuacao = existingResponse.score;
        } else {
          // Calcular pontua√ß√£o usando IA
          try {
            const { candidateEvaluationService } = await import('./candidateEvaluationService');
            const openaiApiKey = process.env.OPENAI_API_KEY;
            
            if (openaiApiKey && currentQuestion.respostaPerfeita && finalTranscription) {
              const evaluationResult = await candidateEvaluationService.evaluateResponse({
                pergunta: currentQuestion.pergunta,
                respostaCandidato: finalTranscription,
                respostaPerfeita: currentQuestion.respostaPerfeita
              });
              
              pontuacao = evaluationResult.pontuacaoGeral;
            } else {
              pontuacao = 0;
            }
          } catch (evaluationError) {
            pontuacao = 0;
          }
        }

        // üîç VERIFICAR SE J√Å EXISTE RESPOSTA PARA ESTA PERGUNTA/CANDIDATO
        const duplicateResponse = existingResponses.find(r => 
          r.questionId === (interview.currentQuestion + 1) && 
          r.candidateId === interview.candidateId &&
          r.selectionId === interview.selectionId
        );

        if (duplicateResponse) {
          // Atualizar resposta existente
          console.log(`üîÑ [UPDATE-CORRIGIDO] Atualizando resposta existente ${duplicateResponse.id}`);
          await storage.updateResponse(duplicateResponse.id, {
            transcription: finalTranscription,
            audioUrl: audioFile ? this.convertToHttpPath(audioFile) : (duplicateResponse.audioUrl || ''),
            score: pontuacao
          });
        } else {
          // üîß CORRE√á√ÉO: Criar nova resposta com transcri√ß√£o final j√° processada
          console.log(`‚ûï [CREATE-CORRIGIDO] Criando nova resposta para pergunta ${interview.currentQuestion + 1}`);
          
          const responseToSave = {
            id: responseId,
            selectionId: interview.selectionId,
            candidateId: interview.candidateId,
            questionId: interview.currentQuestion + 1,
            questionText: currentQuestion.pergunta,
            audioUrl: audioFile ? this.convertToHttpPath(audioFile) : '', // üîß CORRE√á√ÉO: converter para URL HTTP
            transcription: finalTranscription, // üîß CORRE√á√ÉO: finalTranscription j√° √© o texto final
            transcriptionId: transcriptionId,
            timestamp: new Date().toISOString(),
            score: pontuacao,
            aiAnalysis: '',
            recordingDuration: 0,
            candidateName: interview.candidateName,
            candidatePhone: interview.phone,
            // üî• CAMPOS EXTRAS PARA FIREBASE
            clientId: interview.clientId,
            questionNumber: interview.currentQuestion + 1,
            status: 'completed'
          };

          // Salvar no storage local
          await storage.createResponse(responseToSave);
          
          // üî• ETAPA 3: SALVAR TAMB√âM NO FIREBASE COM ESTRUTURA PADRONIZADA
          try {
            const { doc, setDoc } = await import('firebase/firestore');
            const { firebaseDb } = await import('./db');
            
            // Gerar chave padronizada
            const responseKey = `${interview.candidateId}_${interview.selectionId}_R${interview.currentQuestion + 1}`;
            
            const firebaseData = {
              // IDs padronizados
              id: responseKey,
              candidateId: interview.candidateId,
              selectionId: interview.selectionId,
              questionNumber: interview.currentQuestion + 1,
              clientId: interview.clientId,
              
              // Dados da pergunta
              questionId: interview.currentQuestion + 1,
              questionText: currentQuestion.pergunta,
              
              // Dados da resposta
              transcription: finalTranscription,
              audioUrl: audioFile ? this.convertToHttpPath(audioFile) : '',
              
              // Metadados
              phone: interview.phone,
              candidatePhone: interview.phone,
              timestamp: new Date(),
              createdAt: new Date(),
              updatedAt: new Date(),
              
              // Status e score
              score: pontuacao,
              status: 'completed',
              recordingDuration: 0,
              aiAnalysis: 'An√°lise AI processada',
              candidateName: interview.candidateName
            };

            await setDoc(doc(firebaseDb, "interviewResponses", responseKey), firebaseData);
            
            console.log(`‚úÖ [DUAL-SAVE] Resposta salva em storage + Firebase com chave: ${responseKey}`);
            console.log(`‚úÖ [DUAL-SAVE] Transcription: ${finalTranscription.substring(0, 50)}...`);
            
            // üî• ETAPA 5: NOTIFICAR INTEGRA√á√ÉO EM TEMPO REAL
            try {
              const { realtimeIntegrationService } = await import('./realtimeIntegrationService');
              await realtimeIntegrationService.notifyNewResponse(
                interview.selectionId,
                interview.candidateId,
                firebaseData
              );
              console.log(`üîÑ [REALTIME] Notifica√ß√£o enviada para sele√ß√£o ${interview.selectionId}`);
            } catch (realtimeError: any) {
              console.error(`‚ö†Ô∏è [REALTIME] Erro na notifica√ß√£o (continuando):`, realtimeError.message);
            }
            
          } catch (firebaseError: any) {
            console.error(`‚ö†Ô∏è [DUAL-SAVE] Erro Firebase (continuando):`, firebaseError.message);
            // N√£o falhar se Firebase der erro, apenas logar
          }
        }
        
        console.log(`üíæ [SAVE-CORRIGIDO] Resposta salva com transcri√ß√£o: "${finalTranscription.substring(0, 50)}..."`);
      }
    } catch (saveError) {
      console.error(`‚ùå [SAVE-CORRIGIDO] Erro ao salvar resposta para ${interview.phone}:`, saveError);
    }

    // üî• CORRE√á√ÉO CR√çTICA: Avan√ßar para pr√≥xima pergunta APENAS AP√ìS SALVAR
    console.log(`üîÑ [INTERVIEW-ADVANCE] Avan√ßando de pergunta ${interview.currentQuestion} para ${interview.currentQuestion + 1}`);
    interview.currentQuestion++;
    
    // üî• BRIDGE SYNC: ATUALIZAR AMBOS OS SISTEMAS
    this.activeInterviews.set(phone, interview);
    
    // üîß SYNC: Atualizar tamb√©m activeSessions se existir
    const session = this.activeSessions.get(phone);
    if (session) {
      session.currentQuestion = interview.currentQuestion;
      session.responses = interview.responses;
      this.activeSessions.set(phone, session);
      console.log(`üîÑ [BRIDGE-SYNC] currentQuestion atualizado para ${interview.currentQuestion} em ambos sistemas`);
    }

    // üî• VERIFICAR SE ENTREVISTA DEVE FINALIZAR
    if (interview.currentQuestion >= interview.questions.length) {
      console.log(`üèÅ [INTERVIEW-FINISH] Todas as perguntas respondidas (${interview.currentQuestion}/${interview.questions.length}) - finalizando entrevista`);
      await this.finishInterview(phone, interview);
      return;
    }

    // Enviar confirma√ß√£o e pr√≥xima pergunta apenas se houver mais perguntas
    console.log(`‚û°Ô∏è [INTERVIEW-NEXT] Enviando pr√≥xima pergunta ${interview.currentQuestion + 1}/${interview.questions.length}`);
    await this.sendMessage(`${phone}@s.whatsapp.net`, `‚úÖ Resposta recebida! Preparando pr√≥xima pergunta...`, interview.clientId);
    
    setTimeout(async () => {
      // üî• BUSCAR ENTREVISTA ATUALIZADA PARA ENVIO
      const currentInterview = this.activeInterviews.get(phone);
      if (currentInterview) {
        console.log(`üì§ [NEXT-QUESTION] Enviando pergunta ${currentInterview.currentQuestion + 1} para ${phone}`);
        await this.sendNextQuestion(phone, currentInterview);
      } else {
        console.log(`‚ùå [NEXT-QUESTION] Entrevista n√£o encontrada para ${phone} - pode ter sido finalizada`);
      }
    }, 2000);
  }

  private async transcribeAudio(audioPath: string, phone: string): Promise<string> {
    // üîß CORRE√á√ÉO: Validar chave da API primeiro
    const openaiApiKey = process.env.OPENAI_API_KEY;
    if (!openaiApiKey) {
      throw new Error('OPENAI_API_KEY ausente no ambiente');
    }
    
    const fs = await import('fs');
    const path = await import('path');
    
    // üîß CORRE√á√ÉO: Validar se arquivo existe
    if (!fs.existsSync(audioPath)) {
      throw new Error(`Arquivo de √°udio n√£o encontrado: ${audioPath}`);
    }
    
    // üîß CORRE√á√ÉO: Validar tamanho do arquivo
    const { size } = fs.statSync(audioPath);
    if (!isValidAudio(size)) {
      throw new Error(`√Åudio corrompido ou muito pequeno (${size} B, m√≠nimo: ${MIN_AUDIO_SIZE})`);
    }
    
    console.log(`üé§ [WHISPER-CORRIGIDO] Iniciando transcri√ß√£o: ${audioPath} (${size} bytes)`);
    
    try {
      // Usar OpenAI SDK
      const { OpenAI } = await import('openai');
      const openai = new OpenAI({
        apiKey: openaiApiKey
      });

      const result = await openai.audio.transcriptions.create({
        file: fs.createReadStream(audioPath),
        model: 'whisper-1',
        language: 'pt',
        response_format: 'text'
      });
      
      // üîß CORRE√á√ÉO: Whisper j√° retorna string, n√£o objeto
      const transcription = result.trim();
      
      if (transcription && transcription.length > 0) {
        console.log(`‚úÖ [WHISPER-CORRIGIDO] Transcri√ß√£o bem-sucedida: "${transcription.substring(0, 100)}..."`);
        return transcription;
      } else {
        throw new Error('Whisper retornou transcri√ß√£o vazia');
      }
      
    } catch (err: any) {
      // üîß CORRE√á√ÉO: Propagar erro com detalhes para debug
      const errorMsg = `Erro na API Whisper: ${err.response?.data || err.message}`;
      console.error(`‚ùå [WHISPER-CORRIGIDO] ${errorMsg}`);
      throw new Error(errorMsg);
    }
  }

  private async finishInterview(phone: string, interview: ActiveInterview): Promise<void> {
    console.log(`üèÅ [FINISH] Finalizando entrevista para ${phone} - ${interview.responses.length} respostas coletadas`);
    
    // Atualizar status da entrevista no banco
    try {
      if (interview.interviewDbId) {
        await storage.updateInterview(parseInt(interview.interviewDbId), { 
          status: 'completed'
        });
        console.log(`üíæ [FINISH] Status da entrevista ${interview.interviewDbId} atualizado para 'completed'`);
      }
    } catch (error) {
      console.error(`‚ùå [FINISH] Erro ao atualizar status da entrevista:`, error);
    }

    // Mensagem final
    await this.sendMessage(`${phone}@s.whatsapp.net`, 
      `üéâ Parab√©ns ${interview.candidateName}! Voc√™ completou a entrevista para ${interview.jobName}.\n\nüìä Total de respostas: ${interview.responses.length}\n‚úÖ Suas respostas foram registradas com sucesso!\n\nN√≥s retornaremos com o resultado o mais breve poss√≠vel. Obrigado pela participa√ß√£o!`,
      interview.clientId
    );

    // üî• LIMPEZA COMPLETA: Remover entrevista
    this.activeInterviews.delete(phone);
    
    console.log(`‚úÖ [FINISH] Entrevista finalizada e removida para ${phone}`);
  }

  private async stopInterview(phone: string, clientId?: string): Promise<void> {
    const interview = this.activeInterviews.get(phone);
    if (interview) {
      // Atualizar status para cancelada
      try {
        if (interview.interviewDbId) {
          await storage.updateInterview(parseInt(interview.interviewDbId), { 
            status: 'cancelled'
          });
        }
      } catch (error: any) {
      }

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `‚èπÔ∏è Entrevista interrompida. Obrigado pela participa√ß√£o at√© aqui!`,
        interview.clientId
      );
      
      this.activeInterviews.delete(phone);
    } else {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "Nenhuma entrevista ativa encontrada.", clientId);
    }
  }

  private async findCandidate(phone: string, clientId?: string) {
    let candidates;

    if (clientId) {
      candidates = await storage.getCandidatesByClientId(parseInt(clientId));
    }
    
    // üî• CORRE√á√ÉO CR√çTICA: Priorizar candidatos do cliente especificado quando h√° duplicatas
    const matchingCandidates = candidates.filter(c => {
      if (!c.whatsapp) return false;
      const candidatePhone = c.whatsapp.replace(/\D/g, '');
      const searchPhone = phone.replace(/\D/g, '');
      return candidatePhone.includes(searchPhone) || searchPhone.includes(candidatePhone);
    });
    
    if (matchingCandidates.length === 0) {
      return null;
    }
    
    // Se temos clientId espec√≠fico, retornar apenas candidatos desse cliente
    if (clientId) {
      const clientCandidates = matchingCandidates.filter(c => c.clientId.toString() === clientId);
      
      if (clientCandidates.length > 0) {
        const candidate = clientCandidates[0];
        return candidate;
      } else {
        return null;
      }
    }
    
    // Fallback: retornar primeiro candidato encontrado
    const candidate = matchingCandidates[0];
    return candidate;
  }

  private async sendMessage(to: string, text: string, clientId?: string): Promise<void> {
    try {
      // üîí ISOLAMENTO CORRIGIDO: Priorizar userIsolatedRoundRobin para envio de mensagens
      if (clientId) {
        // Mapear clientId para userId (neste sistema, clientId √© o userId)
        const userId = clientId;
        
        try {
          // ‚úÖ CORRE√á√ÉO ARQUITETURAL: Usar userIsolatedRoundRobin como camada √∫nica
          const phoneNumber = to.replace('@s.whatsapp.net', '');
          
          const result = await userIsolatedRoundRobin.sendUserMessage(
            userId,
            clientId,
            phoneNumber,
            text
          );
          
          if (result.success) {
            console.log(`üì§ [CORRIGIDO] Mensagem enviada via slot isolado ${result.usedSlot} do usu√°rio ${userId}`);
            return;
          } else {
            console.log(`‚ö†Ô∏è [CORRIGIDO] Falha no envio isolado para usu√°rio ${userId}: ${result.error}`);
          }
        } catch (isolatedError) {
          console.log(`‚ùå [CORRIGIDO] Erro no envio isolado para usu√°rio ${userId}:`, isolatedError);
        }
        
        // ‚úÖ ARQUITETURA CORRIGIDA: Sem fallback - userIsolatedRoundRobin deve ser suficiente
        console.log(`‚ö†Ô∏è [CORRIGIDO] Tentativa de envio falhou para usu√°rio ${userId}`);
      }
      
      // ‚úÖ ARQUITETURA CORRIGIDA: N√£o usar envio de emerg√™ncia n√£o isolado
      console.log('‚ùå [CORRIGIDO] Envio falhou - mantendo isolamento por usu√°rio');
      
    } catch (error) {
    }
  }

  // M√©todo p√∫blico para verificar entrevistas ativas
  getActiveInterviews(): Map<string, ActiveInterview> {
    return this.activeInterviews;
  }
}

export const interactiveInterviewService = new InteractiveInterviewService();