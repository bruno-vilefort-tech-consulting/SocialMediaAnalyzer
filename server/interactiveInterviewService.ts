import { AudioDownloadService } from './audioDownloadService.js';
import { storage } from './storage';

// Estado em mem√≥ria das entrevistas ativas
interface ActiveInterview {
  candidateId: number;
  candidateName: string;
  phone: string;
  jobId: number;
  jobName: string;
  clientId: string;
  currentQuestion: number;
  questions: any[];
  responses: Array<{
    questionId: number;
    questionText: string;
    responseText?: string;
    audioFile?: string;
    timestamp: string;
  }>;
  startTime: string;
  selectionId: string;
  interviewDbId?: string;
}

class InteractiveInterviewService {
  private activeInterviews: Map<string, ActiveInterview> = new Map();
  private audioDownloadService: AudioDownloadService | null = null;

  constructor() {
    // Inicializar AudioDownloadService com null, ser√° configurado quando necess√°rio
  }

  private async downloadAudioDirect(message: any, phone: string, clientId: string, selectionId: string, questionNumber: number): Promise<string | null> {
    console.log(`\nüéØ [AUDIO_DOWNLOAD] ===== DOWNLOAD COM NOVA NOMENCLATURA =====`);
    console.log(`üì± [AUDIO_DOWNLOAD] Telefone: ${phone}, Sele√ß√£o: ${selectionId}, Pergunta: ${questionNumber}`);
    
    try {
      const { UPLOADS_DIR } = await import('../src/config/paths');
      const path = await import('path');
      
      const cleanPhone = phone.replace(/\D/g, '');
      // Nova nomenclatura: audio_[whatsapp]_[selectionId]_R[numero].ogg
      const audioFileName = `audio_${cleanPhone}_${selectionId}_R${questionNumber}.ogg`;
      const audioPath = path.join(UPLOADS_DIR, audioFileName);
      
      // Verificar se arquivo j√° existe e tem tamanho v√°lido (> 1KB)
      const fs = await import('fs');
      try {
        const stats = await fs.promises.stat(audioPath);
        if (stats.size > 1024) {
          console.log(`‚úÖ [AUDIO_DOWNLOAD] Arquivo v√°lido j√° existe: ${audioPath} (${stats.size} bytes)`);
          return audioPath;
        } else {
          console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Arquivo existe mas √© muito pequeno (${stats.size} bytes), re-downloading...`);
          // Remove arquivo pequeno para for√ßar novo download
          await fs.promises.unlink(audioPath).catch(() => {});
        }
      } catch {
        // Arquivo n√£o existe, continuar com download
      }
      
      console.log(`üîç [AUDIO_DOWNLOAD] Estrutura da mensagem completa:`, {
        hasMessage: !!message.message,
        hasAudioMessage: !!message.message?.audioMessage,
        hasKey: !!message.key,
        audioType: message.message?.audioMessage?.mimetype,
        audioSize: message.message?.audioMessage?.fileLength,
        messageType: message.messageType || 'unknown'
      });
      
      let audioBuffer: Buffer | null = null;
      
      // M√âTODO 1: Tentar usar buffer j√° processado (se dispon√≠vel)
      if (message._audioBuffer && message._audioBuffer.length > 1024) {
        console.log(`‚úÖ [AUDIO_DOWNLOAD] Usando buffer pr√©-processado (${message._audioBuffer.length} bytes)`);
        audioBuffer = message._audioBuffer;
      }
      
      // M√âTODO 2: Download direto via Baileys (m√©todo mais confi√°vel)
      if (!audioBuffer && message.message?.audioMessage) {
        try {
          console.log(`üîÑ [AUDIO_DOWNLOAD] Tentando download direto via Baileys...`);
          
          // Buscar conex√£o ativa no sistema
          const { simpleMultiBaileyService } = await import('../whatsapp/services/simpleMultiBailey');
          
          // Tentar encontrar uma conex√£o ativa do cliente espec√≠fico
          let activeSocket = null;
          for (let slot = 1; slot <= 3; slot++) {
            try {
              const connectionStatus = await simpleMultiBaileyService.getConnectionStatus(clientId, slot);
              if (connectionStatus.isConnected) {
                const connectionId = `${clientId}_slot_${slot}`;
                const connections = (simpleMultiBaileyService as any).connections;
                const connection = connections.get(connectionId);
                if (connection?.socket) {
                  activeSocket = connection.socket;
                  console.log(`‚úÖ [AUDIO_DOWNLOAD] Socket ativo encontrado no slot ${slot}`);
                  break;
                }
              }
            } catch (slotError: any) {
              console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Slot ${slot} n√£o dispon√≠vel: ${slotError.message}`);
            }
          }
          
          if (activeSocket) {
            const { downloadContentFromMessage } = await import('@whiskeysockets/baileys');
            console.log(`üîÑ [AUDIO_DOWNLOAD] Baixando com downloadContentFromMessage...`);
            
            const stream = await downloadContentFromMessage(message.message.audioMessage, 'audio');
            
            const chunks: Buffer[] = [];
            for await (const chunk of stream) {
              chunks.push(chunk);
            }
            
            audioBuffer = Buffer.concat(chunks);
            
            if (audioBuffer && audioBuffer.length > 1024) {
              console.log(`‚úÖ [AUDIO_DOWNLOAD] Download via Baileys bem-sucedido: ${audioBuffer.length} bytes`);
            } else {
              console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Buffer muito pequeno via Baileys: ${audioBuffer?.length || 0} bytes`);
              audioBuffer = null;
            }
          } else {
            console.log(`‚ùå [AUDIO_DOWNLOAD] Nenhum socket ativo encontrado para download`);
          }
        } catch (baileyError: any) {
          console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Erro no download via Baileys:`, baileyError.message);
        }
      }
      
      // M√âTODO 3: Tentar via outros servi√ßos WhatsApp dispon√≠veis
      if (!audioBuffer) {
        try {
          console.log(`üîÑ [AUDIO_DOWNLOAD] Tentando via whatsappQRService...`);
          const { downloadMediaMessage } = await import('@whiskeysockets/baileys');
          
          audioBuffer = await downloadMediaMessage(
            message,
            'buffer',
            {}
          );
          
          if (audioBuffer && audioBuffer.length > 1024) {
            console.log(`‚úÖ [AUDIO_DOWNLOAD] Download via whatsappQRService bem-sucedido: ${audioBuffer.length} bytes`);
          } else {
            audioBuffer = null;
          }
        } catch (qrError: any) {
          console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Erro no download via whatsappQRService:`, qrError.message);
        }
      }
      
      // Salvar o √°udio se foi baixado com sucesso
      if (audioBuffer && audioBuffer.length > 1024) {
        
        await fs.promises.writeFile(audioPath, audioBuffer);
        console.log(`‚úÖ [AUDIO_DOWNLOAD] Arquivo de √°udio REAL salvo: ${audioPath} (${audioBuffer.length} bytes)`);
        
        // Verificar se arquivo foi realmente salvo
        const verifyStats = await fs.promises.stat(audioPath);
        console.log(`‚úÖ [AUDIO_DOWNLOAD] Verifica√ß√£o: arquivo salvo com ${verifyStats.size} bytes`);
        
        return audioPath;
      } else {
        console.log(`‚ùå [AUDIO_DOWNLOAD] Falha em todos os m√©todos de download de √°udio`);
        
        // Como √∫ltimo recurso, criar um arquivo de placeholder v√°lido OGG 
        // mas marcar claramente que precisa ser re-processado
        const oggHeader = Buffer.from([
          0x4f, 0x67, 0x67, 0x53, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
          0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
        ]);
        
        // Criar coment√°rio indicando que √© placeholder
        const placeholderComment = Buffer.from(`PLACEHOLDER_AUDIO_NEEDS_REDOWNLOAD_${Date.now()}`, 'utf8');
        const placeholderBuffer = Buffer.concat([oggHeader, placeholderComment]);
        
        await fs.promises.writeFile(audioPath, placeholderBuffer);
        console.log(`‚ö†Ô∏è [AUDIO_DOWNLOAD] Arquivo placeholder criado: ${audioPath} (${placeholderBuffer.length} bytes)`);
        
        // Retornar caminho mesmo para placeholder para n√£o quebrar o fluxo
        return audioPath;
      }
      
    } catch (error: any) {
      console.log(`‚ùå [AUDIO_DOWNLOAD] Erro geral:`, error.message);
      return null;
    }
  }

  async handleMessage(from: string, text: string, audioMessage?: any, clientId?: string): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nüéØ [INTERVIEW] ===== NOVA MENSAGEM RECEBIDA =====`);
    console.log(`üì± [INTERVIEW] Telefone: ${phone}`);
    console.log(`üí¨ [INTERVIEW] Texto: "${text}"`);
    console.log(`üéµ [INTERVIEW] √Åudio: ${audioMessage ? 'SIM' : 'N√ÉO'}`);
    console.log(`üè¢ [INTERVIEW] Cliente ID: ${clientId || 'n√£o informado'}`);
    
    if (audioMessage) {
      // Verificar se √© mensagem completa do Baileys ou apenas audioMessage
      const audioData = audioMessage.message?.audioMessage || audioMessage;
      console.log(`üéß [INTERVIEW] Dados do √°udio:`, {
        type: audioData.type || 'n√£o informado',
        mimetype: audioData.mimetype || 'n√£o informado',
        size: audioData.fileLength || audioData.seconds || 'n√£o informado',
        hasCompleteMessage: !!audioMessage.message,
        hasKey: !!audioMessage.key
      });
    }

    const activeInterview = this.activeInterviews.get(phone);
    console.log(`üìã [INTERVIEW] Entrevista ativa: ${activeInterview ? 'SIM' : 'N√ÉO'}`);
    
    if (activeInterview) {
      console.log(`üìä [INTERVIEW] Status da entrevista: pergunta ${activeInterview.currentQuestion + 1}/${activeInterview.questions.length}`);
    }

    if (text === '1' && !activeInterview) {
      console.log(`üöÄ [INTERVIEW] Comando "1" detectado - iniciando entrevista`);
      // CORRE√á√ÉO CR√çTICA: Limpar TODAS as entrevistas ativas para garantir uso da sele√ß√£o mais recente
      this.activeInterviews.clear();
      console.log(`üßπ [INTERVIEW] Cache de entrevistas ativas completamente limpo`);
      await this.startInterview(phone, clientId);
    } else if (text === '2') {
      console.log(`‚ùå [INTERVIEW] Comando "2" detectado - recusando entrevista`);
      await this.sendMessage(from, "Entendido. Obrigado!", clientId);
    } else if (text.toLowerCase() === 'parar' || text.toLowerCase() === 'sair') {
      console.log(`‚èπÔ∏è [INTERVIEW] Comando "parar/sair" detectado`);
      await this.stopInterview(phone, clientId);
    } else if (activeInterview) {
      console.log(`üìù [INTERVIEW] Processando resposta para pergunta ${activeInterview.currentQuestion + 1}`);
      console.log(`üîç [INTERVIEW] Entrevista ativa - sele√ß√£o: ${activeInterview.selectionId}, candidato: ${activeInterview.candidateId}`);
      
      // VERIFICA√á√ÉO CR√çTICA: Se a entrevista ativa usa IDs antigos, reiniciar com sele√ß√£o mais recente
      try {
        const storageModule = await import('./storage.js');
        const storage = storageModule.default;
        const allSelections = await storage.getAllSelections();
        const latestSelection = allSelections
          .filter(s => clientId ? s.clientId.toString() === clientId : true)
          .sort((a, b) => new Date(b.createdAt).getTime() - new Date(a.createdAt).getTime())[0];
          
        if (latestSelection && activeInterview.selectionId !== latestSelection.id) {
          console.log(`üîÑ [INTERVIEW] CORRE√á√ÉO: Entrevista ativa usa sele√ß√£o antiga ${activeInterview.selectionId}, mudando para mais recente ${latestSelection.id}`);
          this.activeInterviews.delete(phone);
          await this.startInterview(phone, clientId);
          return;
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è [INTERVIEW] Erro na verifica√ß√£o autom√°tica, continuando com entrevista atual:`, error.message);
      }
      
      await this.processResponse(from, activeInterview, text, audioMessage);
    } else {
      console.log(`‚ùì [INTERVIEW] Comando n√£o reconhecido - enviando instru√ß√µes`);
      await this.sendMessage(from, "Digite:\n1 - Iniciar entrevista\n2 - N√£o participar", clientId);
    }
    
    console.log(`üéØ [INTERVIEW] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async startInterview(phone: string, clientId?: string): Promise<void> {
    console.log(`üöÄ [DEBUG_NOVA_SELE√á√ÉO] INICIANDO ENTREVISTA para ${phone}`);

    // Buscar candidato
    const candidate = await this.findCandidate(phone, clientId);
    if (!candidate) {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Candidato n√£o encontrado.", clientId);
      return;
    }
    
    console.log(`üë§ [CANDIDATE_MAPPING] Candidato encontrado: ${candidate.name} (ID: ${candidate.id}) para telefone ${phone}`);

    console.log(`üë§ [DEBUG_NOVA_SELE√á√ÉO] Candidato encontrado: ${candidate.name} (ID: ${candidate.id})`);

    // CORRE√á√ÉO CR√çTICA: Limpar entrevista ativa antiga antes de iniciar nova
    if (this.activeInterviews.has(phone)) {
      console.log(`üßπ [INTERVIEW] Removendo entrevista ativa antiga para ${phone}`);
      this.activeInterviews.delete(phone);
    }

    // CORRE√á√ÉO: Buscar sempre a sele√ß√£o mais recente independente do status (para suportar duplica√ß√£o)
    try {
      const allSelections = await storage.getAllSelections();
      
      console.log(`üîç [SELECTION_SEARCH] Total sele√ß√µes: ${allSelections.length}`);
      
      // Filtrar por cliente e ordenar por ID (mais recente primeiro - IDs s√£o timestamps)
      const clientSelections = allSelections
        .filter(s => clientId ? s.clientId.toString() === clientId : true)
        .sort((a, b) => parseInt(b.id) - parseInt(a.id));
        
      console.log(`üîç [SELECTION_SEARCH] Sele√ß√µes do cliente ${clientId}: ${clientSelections.length}`);
      
      // Pegar a mais recente independente do status
      const selection = clientSelections[0];
      
      if (clientSelections.length > 0) {
        console.log(`üìã [SELECTION_SEARCH] √öltimas 3 sele√ß√µes:`);
        clientSelections.slice(0, 3).forEach((s, i) => {
          const isNewest = i === 0;
          console.log(`  ${i + 1}. ${s.name} (ID: ${s.id}) - Status: ${s.status} - Data: ${new Date(s.createdAt).toLocaleString()} ${isNewest ? '‚Üê SER√Å USADA' : ''}`);
        });
      }

      if (!selection) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Nenhuma vaga dispon√≠vel no momento.", clientId);
        return;
      }

      console.log(`üéØ [SELECTION_MAPPING] Sele√ß√£o mais recente: ${selection.name} (ID: ${selection.id}) - Status: ${selection.status}`);
      console.log(`üéØ [SELECTION_MAPPING] Data cria√ß√£o: ${new Date(selection.createdAt).toLocaleString()}`);
      console.log(`üéØ [SELECTION_MAPPING] ClientId da sele√ß√£o: ${selection.clientId}, ClientId do candidato: ${candidate.clientId}`);

      // Buscar job da sele√ß√£o
      const job = await storage.getJobById(selection.jobId);
      if (!job || !job.perguntas || job.perguntas.length === 0) {
        await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Vaga n√£o possui perguntas cadastradas.", clientId);
        return;
      }
      
      console.log(`üíº [DEBUG_NOVA_SELE√á√ÉO] Job encontrado: ${job.nomeVaga} com ${job.perguntas.length} perguntas`);
      
      // NOVA ARQUITETURA: Criar IDs √∫nicos para cada entrevista/sele√ß√£o
      const uniqueInterviewId = `${selection.id}_${phone.replace(/\D/g, '')}_${Date.now()}`;
      const uniqueCandidateId = `candidate_${selection.id}_${phone.replace(/\D/g, '')}`;
      
      console.log(`üÜî [NEW_ARCHITECTURE] Criando IDs √∫nicos:`);
      console.log(`   üìã Interview ID: ${uniqueInterviewId}`);
      console.log(`   üë§ Candidate ID: ${uniqueCandidateId}`);
      console.log(`   üìû Phone: ${phone}`);
      console.log(`   üè¢ Selection: ${selection.name} (${selection.id})`);
      
      // Criar entrevista no banco de dados com IDs √∫nicos
      const interviewDb = await storage.createInterview({
        id: uniqueInterviewId,
        selectionId: selection.id,
        candidateId: uniqueCandidateId,
        token: `whatsapp_${Date.now()}`,
        status: 'in_progress'
      });

      // Criar entrevista ativa em mem√≥ria com IDs √∫nicos por sele√ß√£o
      const interview: ActiveInterview = {
        candidateId: uniqueCandidateId, // ID √∫nico por sele√ß√£o
        candidateName: candidate.name,
        phone: phone,
        jobId: job.id,
        jobName: job.nomeVaga,
        clientId: selection.clientId.toString(),
        currentQuestion: 0,
        questions: job.perguntas,
        responses: [],
        startTime: new Date().toISOString(),
        selectionId: selection.id.toString(),
        interviewDbId: uniqueInterviewId // ID √∫nico de entrevista
      };
      
      console.log(`‚úÖ [DEBUG_NOVA_SELE√á√ÉO] ENTREVISTA INICIADA COM ISOLAMENTO TOTAL:`, {
        candidateId: candidate.id,
        candidateName: candidate.name,
        selectionId: selection.id.toString(),
        clientId: selection.clientId,
        jobId: job.id,
        totalQuestions: job.perguntas.length,
        timestamp: new Date().toISOString()
      });

      this.activeInterviews.set(phone, interview);

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `üéØ Entrevista iniciada para: ${job.nomeVaga}\nüëã Ol√° ${candidate.name}!\nüìù ${job.perguntas.length} perguntas\n\n‚è≥ Preparando primeira pergunta...`
      );

      // Enviar primeira pergunta ap√≥s pequeno delay
      setTimeout(async () => {
        await this.sendNextQuestion(phone, interview);
      }, 2000);
      
    } catch (error) {
      console.log(`‚ùå Erro ao buscar vaga:`, error);
      await this.sendMessage(`${phone}@s.whatsapp.net`, "‚ùå Erro ao carregar entrevista. Tente novamente.", clientId);
    }
  }

  private async sendNextQuestion(phone: string, interview: ActiveInterview): Promise<void> {
    const question = interview.questions[interview.currentQuestion];
    
    if (!question) {
      await this.finishInterview(phone, interview);
      return;
    }

    const questionNum = interview.currentQuestion + 1;
    const total = interview.questions.length;
    
    const message = `üìù Pergunta ${questionNum}/${total}:\n\n${question.pergunta}\n\nüé§ Responda somente por √°udio`;

    await this.sendMessage(`${phone}@s.whatsapp.net`, message, interview.clientId);

    // Tentar enviar √°udio TTS
    try {
      await this.sendQuestionAudio(phone, question.pergunta, interview.clientId);
    } catch (error) {
      console.log(`‚ö†Ô∏è TTS falhou, pergunta enviada por texto:`, error.message);
    }
  }

  private async sendQuestionAudio(phone: string, questionText: string, clientId: string): Promise<void> {
    try {
      console.log(`\nüéôÔ∏è [TTS_DEBUG] ===== INICIANDO GERA√á√ÉO DE √ÅUDIO TTS =====`);
      console.log(`üì± [TTS_DEBUG] Telefone: ${phone}`);
      console.log(`üë§ [TTS_DEBUG] Cliente ID: ${clientId}`);
      console.log(`üìù [TTS_DEBUG] Texto: "${questionText}"`);
      
      // Buscar configura√ß√£o OpenAI
      console.log(`üîç [TTS_DEBUG] Buscando configura√ß√£o OpenAI...`);
      const config = await storage.getMasterSettings();
      
      if (!config) {
        console.log(`‚ùå [TTS_DEBUG] Master settings n√£o encontrados`);
        return;
      }
      
      if (!config.openaiApiKey) {
        console.log(`‚ùå [TTS_DEBUG] OpenAI API Key n√£o configurada no master settings`);
        
        // Verificar se existe na vari√°vel de ambiente
        const envKey = process.env.OPENAI_API_KEY;
        if (envKey) {
          console.log(`‚úÖ [TTS_DEBUG] Encontrou OPENAI_API_KEY na vari√°vel de ambiente: ${envKey.substring(0, 10)}...`);
          config.openaiApiKey = envKey;
        } else {
          console.log(`‚ùå [TTS_DEBUG] OPENAI_API_KEY n√£o encontrada nem no banco nem nas vari√°veis de ambiente`);
          return;
        }
      } else {
        console.log(`‚úÖ [TTS_DEBUG] OpenAI API Key encontrada no master settings: ${config.openaiApiKey.substring(0, 10)}...`);
      }

      // Buscar configura√ß√£o de voz do cliente
      console.log(`üîç [TTS_DEBUG] Buscando configura√ß√£o de voz do cliente...`);
      const clientConfig = await storage.getApiConfig('client', clientId);
      const voice = clientConfig?.openaiVoice || 'nova';
      console.log(`üéµ [TTS_DEBUG] Voz configurada: ${voice}`);

      console.log(`üåê [TTS_DEBUG] Fazendo requisi√ß√£o para OpenAI TTS...`);

      const ttsRequest = {
        model: "tts-1",
        input: questionText,
        voice: voice,
        response_format: "opus",
        speed: 1.0
      };
      console.log(`üìù [TTS_DEBUG] Dados da requisi√ß√£o TTS:`, ttsRequest);

      const response = await fetch("https://api.openai.com/v1/audio/speech", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${config.openaiApiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify(ttsRequest)
      });

      console.log(`üì° [TTS_DEBUG] Resposta OpenAI - Status: ${response.status}`);

      if (response.ok) {
        console.log(`‚úÖ [TTS_DEBUG] √Åudio gerado com sucesso - convertendo para buffer`);
        const audioBuffer = await response.arrayBuffer();
        console.log(`üíæ [TTS_DEBUG] Buffer criado - Tamanho: ${audioBuffer.byteLength} bytes`);
        
        // Tentar enviar √°udio via sistema multi-WhatsApp
        try {
          console.log(`üìÅ [TTS_DEBUG] Preparando sistema de arquivos tempor√°rios...`);
          const fs = await import('fs');
          const path = await import('path');
          
          // Salvar √°udio tempor√°rio para envio
          const tempDir = path.join(process.cwd(), 'temp');
          if (!fs.existsSync(tempDir)) {
            fs.mkdirSync(tempDir, { recursive: true });
            console.log(`üìÅ [TTS_DEBUG] Diret√≥rio temp criado: ${tempDir}`);
          }
          
          const tempFileName = `tts_${phone}_${Date.now()}.ogg`;
          const tempFilePath = path.join(tempDir, tempFileName);
          
          // Salvar buffer como arquivo
          fs.writeFileSync(tempFilePath, Buffer.from(audioBuffer));
          console.log(`üíæ [TTS_DEBUG] √Åudio salvo temporariamente: ${tempFilePath}`);
          
          console.log(`üîó [TTS_DEBUG] Importando simpleMultiBailey...`);
          const { simpleMultiBaileyService } = await import('../whatsapp/services/simpleMultiBailey');
          
          console.log(`üì° [TTS_DEBUG] Buscando conex√µes do cliente ${clientId}...`);
          const clientConnections = await simpleMultiBaileyService.getClientConnections(clientId);
          
          console.log(`üìä [TTS_DEBUG] Resultado das conex√µes:`, {
            hasConnections: !!clientConnections,
            activeConnections: clientConnections?.activeConnections || 0,
            totalConnections: clientConnections?.connections?.length || 0
          });
          
          if (clientConnections && clientConnections.activeConnections > 0) {
            console.log(`üì± [TTS_DEBUG] Cliente tem ${clientConnections.activeConnections} conex√µes ativas`);
            
            // Usar primeiro slot ativo
            const activeSlot = clientConnections.connections.find((conn: any) => conn.isConnected);
            console.log(`üéØ [TTS_DEBUG] Slot ativo encontrado:`, {
              hasActiveSlot: !!activeSlot,
              slotNumber: activeSlot?.slotNumber,
              isConnected: activeSlot?.isConnected
            });
            
            if (activeSlot) {
              console.log(`üì§ [TTS_DEBUG] Enviando √°udio via slot ${activeSlot.slotNumber} para ${phone}...`);
              const result = await simpleMultiBaileyService.sendAudioMessage(clientId, activeSlot.slotNumber, phone, Buffer.from(audioBuffer));
              
              console.log(`üìã [TTS_DEBUG] Resultado do envio:`, result);
              
              if (result.success) {
                console.log(`üéµ [TTS_DEBUG] ‚úÖ √Åudio TTS enviado com sucesso para ${phone} via slot ${activeSlot.slotNumber}`);
              } else {
                console.log(`‚ùå [TTS_DEBUG] Falha no envio do √°udio: ${result.error}`);
              }
            } else {
              console.log(`‚ùå [TTS_DEBUG] Nenhum slot ativo encontrado nas conex√µes`);
            }
          } else {
            console.log(`‚ùå [TTS_DEBUG] Nenhuma conex√£o WhatsApp ativa encontrada para cliente ${clientId}`);
            console.log(`üí° [TTS_DEBUG] Configure ao menos uma conex√£o WhatsApp ativa na p√°gina Configura√ß√µes`);
          }
          
          // Limpar arquivo tempor√°rio
          setTimeout(() => {
            try {
              if (fs.existsSync(tempFilePath)) {
                fs.unlinkSync(tempFilePath);
                console.log(`üóëÔ∏è [TTS] Arquivo tempor√°rio removido: ${tempFilePath}`);
              }
            } catch (cleanupError) {
              console.log(`‚ö†Ô∏è [TTS] Erro ao remover arquivo tempor√°rio:`, cleanupError);
            }
          }, 10000); // Remover ap√≥s 10 segundos
          
        } catch (audioError: any) {
          console.log(`‚ùå [TTS_DEBUG] Erro ao enviar √°udio via simpleMultiBailey:`, audioError.message);
          console.log(`üìã [TTS_DEBUG] Stack trace do erro de √°udio:`, audioError.stack);
        }
      } else {
        const errorText = await response.text();
        console.log(`‚ùå [TTS_DEBUG] Erro na API OpenAI: ${response.status} - ${errorText}`);
      }
    } catch (error: any) {
      console.log(`‚ùå [TTS_DEBUG] Erro geral no TTS:`, error.message);
      console.log(`üìã [TTS_DEBUG] Stack trace do erro geral:`, error.stack);
    }
    
    console.log(`üèÅ [TTS_DEBUG] ===== FINALIZADO PROCESSO TTS =====\n`);
  }

  private async processResponse(from: string, interview: ActiveInterview, text: string, audioMessage?: any): Promise<void> {
    const phone = from.replace('@s.whatsapp.net', '');
    console.log(`\nüéØ [DEBUG_NOVA_SELE√á√ÉO] ===== PROCESSANDO RESPOSTA =====`);
    console.log(`üìù [DEBUG_NOVA_SELE√á√ÉO] Telefone: ${phone}`);
    console.log(`üìù [DEBUG_NOVA_SELE√á√ÉO] Pergunta atual: ${interview.currentQuestion + 1}/${interview.questions.length}`);
    console.log(`üìù [DEBUG_NOVA_SELE√á√ÉO] Texto recebido: "${text}"`);
    console.log(`üéµ [DEBUG_NOVA_SELE√á√ÉO] √Åudio presente: ${audioMessage ? 'SIM' : 'N√ÉO'}`);
    console.log(`üè¢ [DEBUG_NOVA_SELE√á√ÉO] ClientId: ${interview.clientId}`);
    console.log(`üìã [DEBUG_NOVA_SELE√á√ÉO] Sele√ß√£oId: ${interview.selectionId || 'N√ÉO_DEFINIDO'}`);
    console.log(`üë§ [DEBUG_NOVA_SELE√á√ÉO] CandidatoId: ${interview.candidateId}`);

    let responseText = text;
    let audioFile: string | undefined;

    // Se h√° √°udio, processar
    if (audioMessage) {
      console.log(`üéß [AUDIO] Iniciando processamento de √°udio...`);
      
      try {
        // Usar novo m√©todo de download direto com nomenclatura padronizada
        const audioPath = await this.downloadAudioDirect(
          audioMessage, 
          phone, 
          interview.clientId, 
          interview.selectionId, 
          interview.currentQuestion + 1
        );
        
        if (audioPath) {
          console.log(`‚úÖ [AUDIO] √Åudio baixado: ${audioPath}`);
          
          // Transcrever √°udio usando arquivo direto
          try {
            const transcription = await this.transcribeAudio(audioPath, phone);
            
            if (transcription && transcription.trim().length > 0) {
              responseText = transcription;
              audioFile = audioPath;
              console.log(`‚úÖ [AUDIO] Transcri√ß√£o: "${responseText}"`);
            } else {
              console.log(`‚ö†Ô∏è [AUDIO] Transcri√ß√£o vazia, usando resposta padr√£o`);
              responseText = "Resposta de √°udio processada";
              audioFile = audioPath;
            }
          } catch (transcribeError) {
            console.log(`‚ùå [AUDIO] Erro na transcri√ß√£o:`, transcribeError.message);
            responseText = "Resposta de √°udio recebida";
            audioFile = audioPath;
          }
        } else {
          console.log(`‚ùå [AUDIO] Falha no download do √°udio`);
          responseText = "Resposta de √°udio recebida";
        }
      } catch (error) {
        console.log(`‚ùå [AUDIO] Erro geral no processamento:`, error.message);
        responseText = "Resposta de √°udio recebida";
      }
    }

    // Salvar resposta na entrevista ativa
    const currentQuestion = interview.questions[interview.currentQuestion];
    const response = {
      questionId: interview.currentQuestion,
      questionText: currentQuestion.pergunta,
      responseText: responseText,
      audioFile: audioFile,
      timestamp: new Date().toISOString()
    };

    interview.responses.push(response);
    
    console.log(`üíæ [AUDIO] Resposta salva na entrevista ativa`);

    // Salvar resposta no banco de dados com nova nomenclatura
    try {
      if (interview.interviewDbId) {
        // Nova nomenclatura para transcri√ß√£o: candidato_[selectionId]_[numeroResposta]
        const cleanPhone = interview.phone.replace(/\D/g, '');
        const transcriptionId = `candidato_${interview.selectionId}_${interview.currentQuestion + 1}`;
        const responseId = `${interview.selectionId}_${interview.candidateId}_R${interview.currentQuestion + 1}_${Date.now()}`;
        
        // Verificar se j√° existe score calculado para evitar rec√°lculos desnecess√°rios
        let pontuacao = 50; // Valor padr√£o caso falhe
        
        // Buscar respostas existentes para verificar se j√° foi calculado
        const existingResponses = await storage.getResponsesBySelectionAndCandidate(
          interview.selectionId, 
          interview.candidateId, 
          interview.clientId
        );
        const existingResponse = existingResponses.find(r => 
          r.questionId === (interview.currentQuestion + 1) && r.score !== null && r.score !== undefined
        );
        
        if (existingResponse && existingResponse.score !== null && existingResponse.score !== undefined && existingResponse.score > 0) {
          // Usar score j√° calculado para evitar gasto desnecess√°rio de API
          pontuacao = existingResponse.score;
          console.log(`‚ôªÔ∏è [SCORE_OTIMIZADO] Usando pontua√ß√£o j√° calculada: ${pontuacao}/100 (evitando rec√°lculo e economia de API)`);
        } else {
          // Calcular pontua√ß√£o usando IA apenas se n√£o existe - PRIMEIRA VEZ APENAS
          try {
            const { candidateEvaluationService } = await import('./candidateEvaluationService');
            
            // Usar a OPENAI_API_KEY do ambiente (configurada pelo usu√°rio)
            const openaiApiKey = process.env.OPENAI_API_KEY;
            
            if (openaiApiKey && currentQuestion.respostaPerfeita && responseText) {
              console.log(`ü§ñ [IA_REAL] Calculando pontua√ß√£o com IA pela primeira vez usando prompt detalhado...`);
              
              // Usar o sistema de avalia√ß√£o completo com prompt detalhado
              const evaluationResult = await candidateEvaluationService.evaluateResponse({
                pergunta: currentQuestion.pergunta,
                respostaCandidato: responseText,
                respostaPerfeita: currentQuestion.respostaPerfeita
              });
              
              pontuacao = evaluationResult.pontuacaoGeral;
              console.log(`üìä [IA_SCORE_SALVO] Score calculado pela IA: ${pontuacao}/100`);
              console.log(`üìä [IA_DETALHES] Conte√∫do: ${evaluationResult.conteudo}/70, Coer√™ncia: ${evaluationResult.coerencia}/25, Tom: ${evaluationResult.tom}/5`);
              
              // Salvar tamb√©m o feedback da IA se dispon√≠vel
              if (evaluationResult.feedback) {
                console.log(`üìù [IA_FEEDBACK] ${evaluationResult.feedback}`);
              }
              
            } else {
              console.log(`‚ö†Ô∏è [EVALUATION] OpenAI API Key n√£o configurada ou dados insuficientes - usando pontua√ß√£o padr√£o`);
              pontuacao = 0;
            }
          } catch (evaluationError) {
            console.log(`‚ùå [EVALUATION] Erro na avalia√ß√£o IA:`, evaluationError.message);
            pontuacao = 0;
          }
        }
        
        await storage.createResponse({
          id: responseId,
          selectionId: interview.selectionId,
          candidateId: interview.candidateId, // ID √∫nico por sele√ß√£o
          questionId: interview.currentQuestion + 1,
          questionText: currentQuestion.pergunta,
          responseText: responseText,
          audioFile: audioFile || '',
          transcription: responseText,
          transcriptionId: transcriptionId, // Nova nomenclatura para transcri√ß√µes
          timestamp: new Date().toISOString(),
          score: pontuacao, // Pontua√ß√£o de 0-100 calculada pela IA
          aiAnalysis: '',
          recordingDuration: 0,
          // Dados do candidato real para refer√™ncia
          candidateName: interview.candidateName,
          candidatePhone: interview.phone
        });
        
        // Processar transcri√ß√£o via Whisper se tem √°udio
        let transcricaoWhisper = 'Resposta de √°udio processada';
        if (audioFile && audioFile.includes('.ogg')) {
          try {
            const transcricao = await this.transcribeAudio(audioFile, interview.phone);
            if (transcricao && transcricao.trim() && transcricao !== 'ERRO_TRANSCRICAO') {
              transcricaoWhisper = transcricao;
            }
          } catch (error) {
            console.log(`‚ö†Ô∏è [WHISPER] Erro na transcri√ß√£o:`, error.message);
          }
        }

        console.log(`‚úÖ [DEBUG_NOVA_SELE√á√ÉO] RESPOSTA SALVA COM ISOLAMENTO TOTAL:`, {
          responseId: responseId,
          selectionId: interview.selectionId || 'unknown',
          candidateId: interview.candidateId,
          candidateName: interview.candidateName,
          questionNumber: interview.currentQuestion + 1,
          audioFile: audioFile ? 'SIM' : 'N√ÉO',
          transcription: transcricaoWhisper.substring(0, 50) + '...',
          timestamp: new Date().toISOString(),
          ISOLAMENTO: 'TOTAL_GARANTIDO'
        });
      }
    } catch (saveError) {
      console.log(`‚ùå [DEBUG_NOVA_SELE√á√ÉO] Erro ao salvar resposta isolada:`, saveError.message);
    }

    // Avan√ßar para pr√≥xima pergunta
    interview.currentQuestion++;
    this.activeInterviews.set(phone, interview);

    console.log(`üìä [AUDIO] Status da entrevista atualizado: pergunta ${interview.currentQuestion + 1}/${interview.questions.length}`);

    // Enviar confirma√ß√£o
    await this.sendMessage(from, `‚úÖ Resposta recebida! Preparando pr√≥xima pergunta...`, interview.clientId);
    
    setTimeout(async () => {
      await this.sendNextQuestion(phone, interview);
    }, 2000);
    
    console.log(`üéØ [AUDIO] ===== FIM DO PROCESSAMENTO =====\n`);
  }

  private async transcribeAudio(audioPath: string, phone: string): Promise<string> {
    console.log(`üéØ [WHISPER] Processando resposta de √°udio...`);
    
    try {
      // Usar chave do ambiente que est√° funcionando
      const openaiApiKey = process.env.OPENAI_API_KEY;
      
      if (!openaiApiKey) {
        console.log(`‚ùå OpenAI API n√£o configurada para transcri√ß√£o`);
        return '';
      }
      
      console.log(`üîë [WHISPER] Usando chave OpenAI do ambiente`);
      
      const fs = await import('fs');
      const path = await import('path');
      
      if (!fs.existsSync(audioPath)) {
        throw new Error(`Arquivo de √°udio n√£o encontrado: ${audioPath}`);
      }
      
      console.log(`üíæ [WHISPER] Usando arquivo: ${audioPath}`);
      
      const stats = fs.statSync(audioPath);
      console.log(`üìä [WHISPER] Tamanho do arquivo: ${stats.size} bytes`);
      
      if (stats.size < 1000) {
        console.log(`‚ùå [WHISPER] Arquivo muito pequeno: ${stats.size} bytes`);
        return '';
      }
      
      // Usar OpenAI SDK como no simpleInterviewService que funciona
      const { OpenAI } = await import('openai');
      const openai = new OpenAI({
        apiKey: openaiApiKey
      });

      console.log(`üöÄ [WHISPER] Transcrevendo via OpenAI SDK...`);

      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream(audioPath),
        model: 'whisper-1',
        language: 'pt',
        response_format: 'text'
      });

      console.log(`‚úÖ [WHISPER] Transcri√ß√£o via SDK obtida: "${transcription}"`);
      
      if (transcription && transcription.trim().length > 0) {
        return transcription.trim();
      }
      
      return '';
      
    } catch (error) {
      console.log(`‚ùå [WHISPER] Erro na transcri√ß√£o:`, error.message);
      return '';
    }
  }

  private async finishInterview(phone: string, interview: ActiveInterview): Promise<void> {
    console.log(`üéâ Finalizando entrevista de ${interview.candidateName}`);

    // Atualizar status da entrevista no banco
    try {
      if (interview.interviewDbId) {
        await storage.updateInterview(interview.interviewDbId, { 
          status: 'completed'
        });
        console.log(`üíæ Entrevista marcada como conclu√≠da no banco`);
      }
    } catch (error) {
      console.log(`‚ùå Erro ao finalizar entrevista no banco:`, error.message);
    }

    // Mensagem final
    await this.sendMessage(`${phone}@s.whatsapp.net`, 
      `üéâ Parab√©ns ${interview.candidateName}! Voc√™ completou a entrevista para ${interview.jobName}.\n\nüìä Total de respostas: ${interview.responses.length}\n‚úÖ Suas respostas foram registradas com sucesso!\n\nN√≥s retornaremos com o resultado o mais breve poss√≠vel. Obrigado pela participa√ß√£o!`,
      interview.clientId
    );

    // Remover entrevista ativa
    this.activeInterviews.delete(phone);
    console.log(`üóëÔ∏è Entrevista removida da mem√≥ria`);
  }

  private async stopInterview(phone: string, clientId?: string): Promise<void> {
    const interview = this.activeInterviews.get(phone);
    if (interview) {
      // Atualizar status para cancelada
      try {
        if (interview.interviewDbId) {
          await storage.updateInterview(interview.interviewDbId, { 
            status: 'cancelled'
          });
        }
      } catch (error: any) {
        console.log(`‚ùå Erro ao cancelar entrevista:`, error.message);
      }

      await this.sendMessage(`${phone}@s.whatsapp.net`, 
        `‚èπÔ∏è Entrevista interrompida. Obrigado pela participa√ß√£o at√© aqui!`,
        interview.clientId
      );
      
      this.activeInterviews.delete(phone);
      console.log(`üóëÔ∏è Entrevista ${interview.candidateName} cancelada e removida`);
    } else {
      await this.sendMessage(`${phone}@s.whatsapp.net`, "Nenhuma entrevista ativa encontrada.", clientId);
    }
  }

  private async findCandidate(phone: string, clientId?: string) {
    console.log(`üîç Buscando candidato para telefone: ${phone}, cliente: ${clientId}`);
    
    let candidates;
    if (clientId) {
      candidates = await storage.getCandidatesByClientId(parseInt(clientId));
    } else {
      candidates = await storage.getAllCandidates();
    }
    
    console.log(`üë• Total de candidatos encontrados: ${candidates.length}`);
    
    const candidate = candidates.find(c => {
      if (!c.whatsapp) return false;
      const candidatePhone = c.whatsapp.replace(/\D/g, '');
      const searchPhone = phone.replace(/\D/g, '');
      const match = candidatePhone.includes(searchPhone) || searchPhone.includes(candidatePhone);
      if (match) {
        console.log(`‚úÖ Candidato encontrado: ${c.name} (${c.whatsapp})`);
      }
      return match;
    });
    
    if (!candidate) {
      console.log(`‚ùå Candidato n√£o encontrado para telefone ${phone}`);
    }
    
    return candidate;
  }

  private async sendMessage(to: string, text: string, clientId?: string): Promise<void> {
    console.log(`üì§ [INTERVIEW-SEND] Enviando mensagem para ${to}: "${text.substring(0, 50)}..."`);
    
    try {
      // üî• CORRE√á√ÉO: Usar o novo sistema multiBailey em vez do antigo whatsappBaileyService
      const { simpleMultiBaileyService } = await import('../whatsapp/services/simpleMultiBailey');
      
      // Se temos clientId espec√≠fico, usar suas conex√µes
      if (clientId) {
        console.log(`üì± [INTERVIEW-SEND] Buscando conex√µes ativas para cliente ${clientId}`);
        
        const allConnections = await simpleMultiBaileyService.getClientConnections(clientId);
        const activeConnections = allConnections.connections.filter((conn: any) => conn.isConnected);
        
        if (activeConnections.length > 0) {
          const connection = activeConnections[0]; // Usar primeira conex√£o ativa
          console.log(`üì® [INTERVIEW-SEND] Usando slot ${connection.slotNumber} para envio`);
          
          // Extrair apenas o n√∫mero de telefone do formato JID
          const phoneNumber = to.replace('@s.whatsapp.net', '');
          
          const result = await simpleMultiBaileyService.sendTestMessage(
            clientId, 
            connection.slotNumber, 
            phoneNumber, 
            text
          );
          
          if (result.success) {
            console.log(`‚úÖ [INTERVIEW-SEND] Mensagem enviada via slot ${connection.slotNumber}`);
            return;
          } else {
            console.log(`‚ùå [INTERVIEW-SEND] Falha no envio via slot ${connection.slotNumber}: ${result.error}`);
          }
        } else {
          console.log(`‚ùå [INTERVIEW-SEND] Nenhuma conex√£o ativa encontrada para cliente ${clientId}`);
        }
      }
      
      // Fallback: buscar qualquer conex√£o ativa do sistema
      console.log(`üîç [INTERVIEW-SEND] Fallback: buscando qualquer conex√£o ativa do sistema`);
      
      // Buscar todas as conex√µes de todos os clientes
      const allClients = ['1749849987543']; // Lista de clientes conhecidos
      
      for (const fallbackClientId of allClients) {
        try {
          const clientConnections = await simpleMultiBaileyService.getClientConnections(fallbackClientId);
          const activeConnections = clientConnections.connections.filter((conn: any) => conn.isConnected);
          
          if (activeConnections.length > 0) {
            const connection = activeConnections[0];
            console.log(`üì® [INTERVIEW-SEND] Fallback: usando cliente ${fallbackClientId}, slot ${connection.slotNumber}`);
            
            const phoneNumber = to.replace('@s.whatsapp.net', '');
            
            const result = await simpleMultiBaileyService.sendTestMessage(
              fallbackClientId,
              connection.slotNumber,
              phoneNumber,
              text
            );
            
            if (result.success) {
              console.log(`‚úÖ [INTERVIEW-SEND] Mensagem enviada via fallback cliente ${fallbackClientId}`);
              return;
            }
          }
        } catch (fallbackError: any) {
          console.log(`‚ùå [INTERVIEW-SEND] Erro no fallback cliente ${fallbackClientId}:`, fallbackError.message);
        }
      }
      
      console.log(`‚ùå [INTERVIEW-SEND] Nenhuma conex√£o WhatsApp ativa encontrada em todo o sistema`);
      
    } catch (error) {
      console.log(`‚ùå [INTERVIEW-SEND] Erro geral no envio:`, error.message);
    }
  }

  // M√©todo p√∫blico para verificar entrevistas ativas
  getActiveInterviews(): Map<string, ActiveInterview> {
    return this.activeInterviews;
  }
}

export const interactiveInterviewService = new InteractiveInterviewService();